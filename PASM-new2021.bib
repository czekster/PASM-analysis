%--------------01st PASM

%01
@article{Geisweiller20053,
title = "Performance Evaluation of a Real-time Simulation Architecture using Probabilistic Model Checking ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "128",
number = "4",
pages = "3 - 24",
year = "2005",
note = "Proceedings of the First International Workshop on Practical Applications of Stochastic Modelling (PASM 2004) Practical Applications of Stochastic Modelling 2004 ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2005.01.010",
url = "http://www.sciencedirect.com/science/article/pii/S1571066105001854",
author = "Nil Geisweiller and Jeremie Bonte",
keywords = "real-time distributed simulation",
keywords = "probabilistic model checking",
keywords = "performance evaluation",
keywords = "\{PEPA\}",
keywords = "\{PRISM\} ",
abstract = "The goal of this paper is to show how to use probabilistic model checking techniques in order to achieve quantitative performance evaluation of a real-time distributed simulation. A simulation based on the High Level Architecture (HLA) is modelled as a stochastic process, a Continuous Time Markov Chain (CTMC), using the stochastic algebra PEPA. Next a property representing a performance constraint is evaluated applying Continuous Stochastic Logic \{CSL\} formula on the \{CTMC\} model using the probabilistic model checker PRISM. Finally a first experiment is made to compare the model with a real case. "
}

%02
@article{Horváth200525,
title = "Analysis of a BMAP/D/1-Timer Multiplexer ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "128",
number = "4",
pages = "25 - 44",
year = "2005",
note = "Proceedings of the First International Workshop on Practical Applications of Stochastic Modelling (PASM 2004) Practical Applications of Stochastic Modelling 2004 ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2005.01.011",
url = "http://www.sciencedirect.com/science/article/pii/S1571066105001866",
author = "Gábor Horváth and Miklós Telek",
keywords = "multiplexer queue",
keywords = "\{BMAP\}",
keywords = "matrix geometric method",
keywords = "waiting time distribution ",
abstract = "In this paper we introduce and analyze a model of a multiplexer queue with a batch Markovian arrival process and a special, timer based, non-work-conserving service discipline. We show that the embedded process at departures is an M/G/1 type process with proper state partitioning, which can be efficiently analyzed by matrix geometric methods. We derive the expressions to compute the distribution of the waiting time. The paper ends with numerical experiments, and points out some interesting features of the system. "
}

%03
@article{Thomas200545,
title = "Performability of a Secure Electronic Voting Algorithm ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "128",
number = "4",
pages = "45 - 58",
year = "2005",
note = "Proceedings of the First International Workshop on Practical Applications of Stochastic Modelling (PASM 2004) Practical Applications of Stochastic Modelling 2004 ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2005.01.012",
url = "http://www.sciencedirect.com/science/article/pii/S1571066105001878",
author = "Nigel Thomas",
keywords = "secure voting scheme",
keywords = "performance modelling",
keywords = "\{PEPA\} ",
abstract = "This paper considers modelling the performance and reliability of a secure electronic voting scheme. The scheme provides secure verifiable blind voting, however there is a considerable administration overhead to this level of security. A Markovian process algebra is used to build a performance model of a basic system of n distributed voters. This model is shown to suffer from the familiar state space explosion problem. A simpler model is therefore developed to allow larger and more practically relevant systems to be studied. The original model is then extended to include the possibility that voters may fail and two modes of recovery are considered. The models are evaluated numerically using data obtained from measuring an implementation of this scheme in order to determine the accuracy of the approximations. "
}

%04
@article{Bellettini200559,
title = "Quantitative Assessment of a Peer-to-peer Cooperative Infrastructure Using Stochastic Well-Formed Nets ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "128",
number = "4",
pages = "59 - 77",
year = "2005",
note = "Proceedings of the First International Workshop on Practical Applications of Stochastic Modelling (PASM 2004) Practical Applications of Stochastic Modelling 2004 ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2005.01.013",
url = "http://www.sciencedirect.com/science/article/pii/S157106610500188X",
author = "Carlo Bellettini and Lorenzo Capra and Mattia Monga",
keywords = "\{SWNs\}",
keywords = "peer-to-peer",
keywords = "configuration management ",
abstract = "Traditional support tools for software engineers, normally based on a client-server architecture, are unsuitable to deal with the new issues emerging from the current (and future) cooperative work scenarios (where connectivity is intrinsically transient, the number of interacting partners dynamically changes, etc.). This paper presents a quantitative assessment of a fully decentralized, peer-to-peer, cooperative infrastructure. Stochastic Well-Formed Nets (SWNs) modelling the new peer-to-peer architecture, and a traditional (client-server) one, are developed and analysed: we used \{SWNs\} for their ability to directly exploit the symmetries intrinsically present in the modelled systems, thus greatly reducing the complexity of the analysis. The main goal is to compare the impact of the two alternative protocols on the collaborative work. Together with the performance figures of interest, methodological issues concerning the choice of the most appropriate model abstraction level, the adoption of a compositional modelling approach, and the management of the model complexity are also discussed. "
}

%05
@article{Gaeta200579,
title = "Fluid Stochastic Petri Nets for Computing Transfer Time Distributions in Peer-to-Peer File Sharing Applications ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "128",
number = "4",
pages = "79 - 99",
year = "2005",
note = "Proceedings of the First International Workshop on Practical Applications of Stochastic Modelling (PASM 2004) Practical Applications of Stochastic Modelling 2004 ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2005.01.014",
url = "http://www.sciencedirect.com/science/article/pii/S1571066105001891",
author = "R. Gaeta and M. Gribaudo and D. Manini and M. Sereno",
keywords = "Peer-to-Peer Systems",
keywords = "File-Sharing Applications",
keywords = "Fluid Stochastic Petri Nets ",
abstract = "This paper presents an application of the Fluid Stochastic Petri Net (FSPN) formalism for the analysis of the transfer time distribution in peer-to-peer (P2P) file sharing applications. The transfer of the resource follows a successful search; the transfer time is mainly dominated by network characteristics, application characteristics, resource characteristics, and user behavior. The proposed analytical modeling technique accounts all these aspects and provides an estimation of the transfer time distribution after the search for a given resource has been performed. Some numerical results are presented to prove the flexibility and the potential of the proposed technique. "
}

%06
@article{Baldo2005101,
title = "Performance Models For Master/Slave Parallel Programs ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "128",
number = "4",
pages = "101 - 121",
year = "2005",
note = "Proceedings of the First International Workshop on Practical Applications of Stochastic Modelling (PASM 2004) Practical Applications of Stochastic Modelling 2004 ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2005.01.015",
url = "http://www.sciencedirect.com/science/article/pii/S1571066105001908",
author = "Lucas Baldo and Leonardo Brenner and Luiz Gustavo Fernandes and Paulo Fernandes and Afonso Sales",
keywords = "performance evaluation",
keywords = "analytical models",
keywords = "stochastic automata networks",
keywords = "parallel programming",
keywords = "propagation algorithm ",
abstract = "This paper proposes the use of Stochastic Automata Networks (SAN) to develop models that can be efficiently applied to a large class of parallel implementations: master/slave (m/s) programs. We focus our technique in the description of the communication between master and slave nodes considering two standard behaviors: synchronous and asynchronous interactions. Although the \{SAN\} models may help the pre-analysis of implementations, the main contribution of this paper is to point out advantages and problems of the proposed modeling technique. "
}

%07
@article{Buchholtz2005123,
title = "Securing Statically-verified Communications Protocols Against Timing Attacks ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "128",
number = "4",
pages = "123 - 143",
year = "2005",
note = "Proceedings of the First International Workshop on Practical Applications of Stochastic Modelling (PASM 2004) Practical Applications of Stochastic Modelling 2004 ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2005.01.016",
url = "http://www.sciencedirect.com/science/article/pii/S157106610500191X",
author = "Mikael Buchholtz and Stephen Gilmore and Jane Hillston and Flemming Nielson",
abstract = "We present a federated analysis of communication protocols which considers both security properties and timing. These are not entirely independent observations of a protocol; by using timing observations of an executing protocol it is possible to calculate encryption keys which were intended to be secret or to deduce derived information about the nature of the communication even in the presence of unbreakable encryption. Our analysis is based on expressing the protocol as a high-level model and deriving from this process calculus models analysable by the Imperial \{PEPA\} Compiler and the LySatool. "
}

%08
@article{Harrison2005145,
title = "Calibration of a Queueing Model of \{RAID\} Systems ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "128",
number = "4",
pages = "145 - 164",
year = "2005",
note = "Proceedings of the First International Workshop on Practical Applications of Stochastic Modelling (PASM 2004) Practical Applications of Stochastic Modelling 2004 ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2005.01.017",
url = "http://www.sciencedirect.com/science/article/pii/S1571066105001921",
author = "Peter G. Harrison and Soraya Zertal",
keywords = "queueing model",
keywords = "\{RAID\} system",
keywords = "mean response time ",
abstract = "A recent queueing-based modelling methodology of \{RAID\} systems compared the mean disk access times of the two most common variants, RAID0-1 and RAID5, as well as a multi-RAID system in which they coexist. Accesses to multiple disks occur concurrently for each logical (user) request and complete only when every disk involved has completed. The models therefore needed to estimate the mean value of the maximum of the individual disk response times, each of which is modelled by the waiting time of an M/G/1 queue. This mean-max value was approximated in terms of the second moment of queueing time which in turn required the third moment of disk service time, itself a function of seek time, rotational latency and block transfer time. To achieve consistently good agreement with an event-driven simulator of the physical hardware and system software requires careful calibration of the resulting model's parameters and validation of its assumptions. This calibration and validation process involves detailed analysis of sub-models to reveal the restrictions necessary on the domain of real-world operating parameters that facilitate a viable predictive model. The process yields significant insight into several of the abstract subsystems involved that may be utilised in a range of practical modelling studies; for example, the effect of approximating a bank of parallel queues with synchronised arrivals by a bank of identical, independent queues. The final comparison against the hardware simulator shows excellent agreement, far surpassing that of the original model. "
}

%--------------02nd PASM

%09
@article{Bradley20065,
title = "Stochastic Simulation Methods Applied to a Secure Electronic Voting Model ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "151",
number = "3",
pages = "5 - 25",
year = "2006",
note = "Proceedings of the Second International Workshop on the Practical Application of Stochastic Modeling (PASM 2005) Proceedings of the Second International Workshop on the Practical Application of Stochastic Modeling (PASM 2005) ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2006.03.009",
url = "http://www.sciencedirect.com/science/article/pii/S1571066106003562",
author = "Jeremy T. Bradley and Stephen T. Gilmore",
keywords = "Stochastic process algebra",
keywords = "\{PEPA\}",
keywords = "course-of-values times series",
keywords = "secure electronic voting ",
abstract = "We demonstrate a novel simulation technique for analysing large stochastic process algebra models, applying this to a secure electronic voting system example. By approximating the discrete state space of a \{PEPA\} model by a continuous equivalent, we can draw on rate equation simulation techniques from both chemical and biological modelling to avoid having to directly enumerate the huge state spaces involved. We use stochastic simulation techniques to provide traces of course-of-values time series representing the number of components in a particular state. Using such a technique we can get simulation results for models exceeding 1010000 states within only a few seconds. "
}

%10
@article{Gilmore200627,
title = "Estimating the Cost of Native Method Calls for Resource-bounded Functional Programming Languages ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "151",
number = "3",
pages = "27 - 45",
year = "2006",
note = "Proceedings of the Second International Workshop on the Practical Application of Stochastic Modeling (PASM 2005) Proceedings of the Second International Workshop on the Practical Application of Stochastic Modeling (PASM 2005) ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2006.03.010",
url = "http://www.sciencedirect.com/science/article/pii/S1571066106003574",
author = "Stephen Gilmore and Olha Shkaravska",
keywords = "Resource-bounded functional programming languages",
keywords = "native method calls",
keywords = "object-oriented virtual machine ",
abstract = "We address the problem of applying resource-bounded functional programming languages in practice on object-oriented virtual machines which include calls to native methods coded in low-level languages without garbage collection support. We consider the application of a functional language with a high-level type system which incorporates measures of heap space consumption in types on such an execution platform. We supplement the syntactic type inference procedure of the functional language with a separate analysis which estimates the costs of memory leaks incurred by calls to garbage collection-ignorant functions. "
}

%11
@article{Harder200647,
title = "Observing Internet Worm and Virus Attacks with a Small Network Telescope ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "151",
number = "3",
pages = "47 - 59",
year = "2006",
note = "Proceedings of the Second International Workshop on the Practical Application of Stochastic Modeling (PASM 2005) Proceedings of the Second International Workshop on the Practical Application of Stochastic Modeling (PASM 2005) ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2006.03.011",
url = "http://www.sciencedirect.com/science/article/pii/S1571066106003586",
author = "Uli Harder and Matt W. Johnson and Jeremy T. Bradley and William J. Knottenbelt",
keywords = "Internet worm attack",
keywords = "malware monitoring",
keywords = "network telescope ",
abstract = "A network telescope is a portion of \{IP\} address space dedicated to observing inbound internet traffic. The purpose of a network telescope is to detect and log malicious traffic which originates from internet worms and viruses. In this paper, we investigate the statistical properties of observed traffic from a passive Class C telescope over a total of three months. We observe that only a few \{IP\} sources and destination ports are responsible for the majority of the traffic. We also demonstrate various ways to visualise the traffic profile from a telescope. We show that specific profiles can identify and distinguish portscans, hostscans and distributed denial-of-service (DDOS) attacks. Looking at the inter-arrival time of packets, the power spectrum and the detrended fluctuation analysis of the observed traffic, we show that there is very little sign of long-range dependence. This is in stark contrast to other network traffic and presents exciting possibilities for identifying malicious traffic purely from its traffic profile. "
}

%12
@article{Harrison200661,
title = "Process Algebraic Non-product-forms ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "151",
number = "3",
pages = "61 - 76",
year = "2006",
note = "Proceedings of the Second International Workshop on the Practical Application of Stochastic Modeling (PASM 2005) Proceedings of the Second International Workshop on the Practical Application of Stochastic Modeling (PASM 2005) ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2006.03.012",
url = "http://www.sciencedirect.com/science/article/pii/S1571066106003598",
author = "P.G. Harrison",
keywords = "Markov processes",
keywords = "Reversed Compound Agent Theorem",
keywords = "non-product form",
keywords = "stochastic modeling ",
abstract = "A generalization of the Reversed Compound Agent Theorem of Markovian process algebra is derived that yields separable, but non-product-form solutions for collections of interacting processes such as arise in multi-class queueing networks with Processor Sharing servers. It is based on an analysis of the minimal cycles in the state space of a multi-agent cooperation, which can be simply identified. The extended methodology leads to what we believe are new separable solutions and, more generally, the results represent a viable practical application of the theory of Markovian process algebras in stochastic modelling. "
}

%13
@article{Kubicek200677,
title = "Applying a Stochastic Model to a Dynamic, QoS Enabled Web Services Hosting Environment ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "151",
number = "3",
pages = "77 - 95",
year = "2006",
note = "Proceedings of the Second International Workshop on the Practical Application of Stochastic Modeling (PASM 2005) Proceedings of the Second International Workshop on the Practical Application of Stochastic Modeling (PASM 2005) ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2006.03.013",
url = "http://www.sciencedirect.com/science/article/pii/S1571066106003604",
author = "Charles Kubicek",
keywords = "Quality of Service",
keywords = "Dynamic Resource Allocation",
keywords = "Stochastic Modelling ",
abstract = "Data centres which host Web services for other organisations and users in a Grid environment must provide for Quality of Service (QoS) requirements to be specified to ensure deployed services perform as desired. As services hosted by a data centre receive unpredictable rates of demand, servers must be allocated dynamically to service pools that are over utilised to avoid breaking QoS requirements. This work describes how a cost based stochastic model for resource allocation is used in data centre middleware to balance server utilisation, and how the model was used to enable a data centre to meet QoS requirements. The stochastic QoS model is compared to two other QoS models and is shown to be the most effective in a number of experiments. "
}

%14
@article{Fourneau200697,
title = "Convergence Routing under Bursty Traffic: Instability and an \{AIMD\} Controller ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "151",
number = "3",
pages = "97 - 109",
year = "2006",
note = "Proceedings of the Second International Workshop on the Practical Application of Stochastic Modeling (PASM 2005) Proceedings of the Second International Workshop on the Practical Application of Stochastic Modeling (PASM 2005) ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2006.03.014",
url = "http://www.sciencedirect.com/science/article/pii/S1571066106003616",
author = "J.M. Fourneau and D. Nott",
keywords = "optical packet switching",
keywords = "convergence routing",
keywords = "admission control",
keywords = "distribution of transport time",
keywords = "congestion",
keywords = "throughput",
keywords = "simulation ",
abstract = "Routing in all optical networks is an important issue. Deflection routing provides a high throughput but suffers from unbounded transportation time. Convergence routing provides ending guarantee to packets entering the network. We focus on the Eulerian routing technique (convergence routing based on an Eulerian directed cycle), and several improvements which increase the throughput. In this paper, we show that these routing algorithms are very unstable when the traffic occurs by bursts. Thus an admission control is needed to maintain a high throughput. "
}

%15
@article{Shaw2006111,
title = "Automatic Parameterisation of Stochastic Petri Net Models of Biological Networks ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "151",
number = "3",
pages = "111 - 129",
year = "2006",
note = "Proceedings of the Second International Workshop on the Practical Application of Stochastic Modeling (PASM 2005) Proceedings of the Second International Workshop on the Practical Application of Stochastic Modeling (PASM 2005) ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2006.03.015",
url = "http://www.sciencedirect.com/science/article/pii/S1571066106003628",
author = "Oliver Shaw and Jason Steggles and Anil Wipat",
keywords = "Petri nets",
keywords = "Genetic Algorithms",
keywords = "Systems Biology",
keywords = "Kinetic parameters",
keywords = "Stochastic simulation ",
abstract = "Stochastic simulations are able to capture the fine grain behaviour and randomness of outcome of biological networks not captured by deterministic techniques. As such they are becoming an increasingly important tool in the biological community. However, current efforts in the stochastic simulation of biological networks are hampered by two main problems: firstly the lack of complete knowledge of kinetic parameters; and secondly the computational cost of the simulations. In this paper we investigate these problems using the framework of stochastic Petri nets. We present a new stochastic Petri net simulation tool \{NASTY\} which allows large numbers of stochastic simulations to be carried out in parallel. We then begin to address the important problem of incomplete knowledge of kinetic parameters by developing a distributed genetic algorithm, based on NASTY's simulation engine, to parameterise stochastic networks. Our algorithm is able to successfully estimate kinetic parameters to replicate a system's behaviour and we illustrate this by presenting a case study in which the kinetic parameters are derived for a stochastic model of the stress response pathway in the bacterium E.coli. "
}

%16
@article{Chanin2006131,
title = "Analytical Modeling for Operating System Schedulers on \{NUMA\} Systems ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "151",
number = "3",
pages = "131 - 149",
year = "2006",
note = "Proceedings of the Second International Workshop on the Practical Application of Stochastic Modeling (PASM 2005) Proceedings of the Second International Workshop on the Practical Application of Stochastic Modeling (PASM 2005) ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2006.03.016",
url = "http://www.sciencedirect.com/science/article/pii/S157106610600363X",
author = "Rafael Chanin and Mônica Corrêa and Paulo Fernandes and Afonso Sales and Roque Scheer and Avelino F. Zorzo",
keywords = "performance evaluation",
keywords = "analytical models",
keywords = "stochastic automata networks",
keywords = "operating system scheduling ",
abstract = "Performance evaluation by benchmarking is one of the main approaches for measuring performance of a computer system. However, it is important to measure parts of a system before they are even implemented. This can be achieved through an analytical description of the system, allowing the analysis of the system performance. Additionally, the analytical model can be extended to consider also reliability issues. This paper presents a generic model for an Operating System (OS) scheduler using the Stochastic Automata Networks (SAN) formalism. \{SAN\} are used to describe processes and processors in the \{OS\} and their behavior when processes have to be migrated. Moreover, processor failures are also modeled in order to provide reliability indices. The proposed model uses actual benchmarks results obtained from a 4-processor Itanium2 \{SMP\} machine and a 12-processor Itanium2 \{NUMA\} machine. "
}

%--------------03rd PASM

%17
@article{Harrison20095,
title = "Bus Modelling in Zoned Disks \{RAID\} Storage Systems ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "232",
number = "0",
pages = "5 - 16",
year = "2009",
note = "Proceedings of the Third International Workshop on the Practical Application of Stochastic Modelling (PASM 2008) ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2009.02.047",
url = "http://www.sciencedirect.com/science/article/pii/S1571066109000528",
author = "Peter Harrison and Soraya Zertal",
keywords = "Multi-RAID",
keywords = "zoned disks",
keywords = "M/G/1 queues",
keywords = "\{IO\} and bus modelling",
keywords = "simulation ",
abstract = "A model of bus contention in a Multi-RAID storage architecture is presented. Based on an M/G/1 queue, the main issues are to determine the service time distribution that accurately represents the highly mixed input traffic of requests. This arises from the coexistence of different \{RAID\} organisations that generate several types of physical request (read/write for each \{RAID\} level) with different related sizes. The size distributions themselves are made more complex by the striping mechanism, with full/large/small stripes in RAID5. We show the impact of the bus traffic on the system's overall performance as predicted by the model and validated against a simulation of the hardware, using common workload assumptions. "
}

%18
@article{Ciocchetta200917,
title = "Integrated Simulation and Model-Checking for the Analysis of Biochemical Systems ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "232",
number = "0",
pages = "17 - 38",
year = "2009",
note = "Proceedings of the Third International Workshop on the Practical Application of Stochastic Modelling (PASM 2008) ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2009.02.048",
url = "http://www.sciencedirect.com/science/article/pii/S157106610900053X",
author = "Federica Ciocchetta and Stephen Gilmore and Maria Luisa Guerriero and Jane Hillston",
keywords = "Systems biology",
keywords = "process algebra",
keywords = "model-checking",
keywords = "stochastic simulation ",
abstract = "Model-checking can provide valuable insight into the behaviour of biochemical systems, answering quantitative queries which are more difficult to answer using stochastic simulation alone. However, model-checking is a computationally intensive technique which can become infeasible if the system under consideration is too large. Moreover, the finite nature of the state representation used means that a priori bounds must be set for the numbers of molecules of each species to be observed in the system. In this paper we present an approach which addresses these problems by using stochastic simulation and the \{PRISM\} model checker in tandem. The stochastic simulation identifies reasonable bounds for molecular populations in the context of the considered experiment. These bounds are used to parameterise the \{PRISM\} model and limit its state space. A simulation pre-run identifies interesting time intervals on which model-checking should focus, if this information is not available from experimental data. "
}

%19
@article{Ballarini200939,
title = "Studying Irreversible Transitions in a Model of Cell Cycle Regulation ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "232",
number = "0",
pages = "39 - 53",
year = "2009",
note = "Proceedings of the Third International Workshop on the Practical Application of Stochastic Modelling (PASM 2008) ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2009.02.049",
url = "http://www.sciencedirect.com/science/article/pii/S1571066109000541",
author = "Paolo Ballarini and Tommaso Mazza and Alida Palmisano and Attila Csikasz-Nagy",
keywords = "Budding Yeast",
keywords = "Cell Cycle",
keywords = "Probabilistic Model Checking",
keywords = "BlenX",
keywords = "Stochastic Simulation ",
abstract = "Cells life follows a cycling behaviour which starts at cell birth and leads to cell division through a number of distinct phases. The transitions through the various cell cycle phases are controlled by a complex network of signalling pathways. Many cell cycle transitions are irreversible: once they are started they must reach completion. In this study we investigate the existence of conditions which lead to cases when irreversibility may be broken. Specifically, we characterise the elements of the cell cycle signalling network that are responsible for the irreversibility and we determine conditions for which the irreversible transitions may become reversible. We illustrate our results through a formal approach in which stochastic simulation analysis and model checking verification are combined. Through probabilistic model checking we provide a quantitative measure for the probability of irreversibility in the “Start” transition of the cell cycle. "
}

%20
@article{Garelli200955,
title = "Performance Analysis of the \{ARIA\} Adaptive Media Processing Workflows using Colored Petri Nets ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "232",
number = "0",
pages = "55 - 73",
year = "2009",
note = "Proceedings of the Third International Workshop on the Practical Application of Stochastic Modelling (PASM 2008) ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2009.02.050",
url = "http://www.sciencedirect.com/science/article/pii/S1571066109000553",
author = "Maurizio Garelli and Marco Gribaudo",
keywords = "Multimedia",
keywords = "Adaptive Media Processing",
keywords = "Performance Evaluation",
keywords = "Colored Petri Nets",
keywords = "Statistical Analysis ",
abstract = "Multimedia systems are one of the most complex and interesting applications that are nowadays proposed to the users. Their complexity derives mainly from the fact that multimedia systems have to process huge amounts of data, while respecting real-time deadlines. For this reason performance evaluation of the underlaying workflow is a key issue in the design process of a new Multimedia system. In this paper we consider the \{ARchitecture\} for Interactive Arts (ARIA), an adaptive media processing workflow, developed at the Arizona State University, and outline a semi-automatic procedure to translate its specification into Colored Petri Nets. We then provide guidelines on how to compute the parameters for the performance models, and apply the proposed methodology to a realistic example of a face recognition application. "
}

%21
@article{Dingle200975,
title = "Automated Customer-Centric Performance Analysis of Generalised Stochastic Petri Nets Using Tagged Tokens ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "232",
number = "0",
pages = "75 - 88",
year = "2009",
note = "Proceedings of the Third International Workshop on the Practical Application of Stochastic Modelling (PASM 2008) ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2009.02.051",
url = "http://www.sciencedirect.com/science/article/pii/S1571066109000565",
author = "Nicholas J. Dingle and William J. Knottenbelt",
keywords = "Generalised stochastic Petri net",
keywords = "tagged tokens",
keywords = "Performance Trees ",
abstract = "Since tokens in Generalised Stochastic Petri Net (GSPN) models are indistinguishable, it is not always possible to reason about customer-centric performance measures. To remedy this, we propose “tagged tokens” – a variant of the “tagged customer” technique used in the analysis of queueing networks. Under this scheme, one token in a structurally restricted net is “tagged” and its position tracked as it moves around the net. Performance queries can then be phrased in terms of the position of the tagged token. To date, the tagging of customers or tokens has been a time-consuming, manual and model-specific process. By contrast, we present here a completely automated methodology for the tagged token analysis of GSPNs. We first describe an intuitive graphical means of specifying the desired tagging configuration, along with the constraints on \{GSPN\} structure which must be observed for tagged tokens to be incorporated. We then present the mappings required for automatically converting a \{GSPN\} with a user-specified tagging structure into a Coloured \{GSPN\} (CGSPN), and thence into an unfolded \{GSPN\} which can be analysed for performance measures of interest by existing tools. We further show how our methodology integrates with Performance Trees, a formalism for the specification of performance queries. We have implemented our approach in the open source \{PIPE\} Petri net tool, and use this to illustrate the extra expressibility granted by tagged tokens through the analysis of a \{GSPN\} model of a hospital's Accident and Emergency department. "
}

%22
@article{Gilly200989,
title = "A Statistically Customisable Web Benchmarking Tool ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "232",
number = "0",
pages = "89 - 99",
year = "2009",
note = "Proceedings of the Third International Workshop on the Practical Application of Stochastic Modelling (PASM 2008) ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2009.02.052",
url = "http://www.sciencedirect.com/science/article/pii/S1571066109000577",
author = "Katja Gilly and Carlos Quesada-Granja and Salvador Alcaraz and Carlos Juiz and Ramon Puigjaner",
keywords = "Web Benchmarking",
keywords = "Dynamic and Static \{HTTP\} traffic ",
abstract = "We describe a statistically customisable solution for Web benchmarking that includes three utilities: an Internet traffic generator for \{HTTP\} traffic, an static and dynamic Web pages generator in the Web server that is going to be tested and a performance monitor that reports some performance metrics during the test. The design of the tool is based on the implementation of the most important probability distributions that mainly characterise statistical properties of Internet traffic like the inter-arrival rate of the incoming Web traffic to the server, the number of objects contained in a Web page and the size of these Web objects. These properties can be customised for a specific capacity planning analysis. In this work, we describe the generation process of the Web pages and the customisable traffic characterization used by the benchmark. The monitoring process details and the validation of the probability distributions implemented are also included. "
}

%23
@article{Osman2009101,
title = "Application of Queueing Network Models in the Performance Evaluation of Database Designs ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "232",
number = "0",
pages = "101 - 124",
year = "2009",
note = "Proceedings of the Third International Workshop on the Practical Application of Stochastic Modelling (PASM 2008) ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2009.02.053",
url = "http://www.sciencedirect.com/science/article/pii/S1571066109000589",
author = "Rasha Osman and Irfan Awan and Michael E. Woodward",
keywords = "Database design performance",
keywords = "queueing networks ",
abstract = "In this paper, we model database designs using queueing networks, giving visibility to the dynamic behaviour of the database design and allowing the database designer to experiment with different design decisions. Our approach is to abstract away the more detailed levels of the database system design by concentrating on the information that is available to the database designer at design time. It differs from other methods of database system performance evaluation in that the performance assessment is specifically targeted at the database design, not at the database system software architecture. We present a bottleneck evaluation of the Transaction Processing Performance Council TPC-C benchmark under different workload conditions and demonstrate how this affects database design decisions. "
}

%24
@article{Czachórski2009125,
title = "Diffusion Approximation Model of Multiserver Stations with Losses ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "232",
number = "0",
pages = "125 - 143",
year = "2009",
note = "Proceedings of the Third International Workshop on the Practical Application of Stochastic Modelling (PASM 2008) ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2009.02.054",
url = "http://www.sciencedirect.com/science/article/pii/S1571066109000590",
author = "Tadeusz Czachórski and Jean-Michel Fourneau and Tomasz Nycz and Ferhan Pekergin",
keywords = "diffusion approximation",
keywords = "transient analysis",
keywords = "G / G / N / N / queue",
keywords = "call center",
keywords = "sliding window mechanism ",
abstract = "The article presents a diffusion approximation model of a G / G / N / N station – N parallel servers without queueing. Diffusion approximation allows us to include in queueing models fairly general assumptions. First of all it gives us a tool to consider in a natural way transient states of queues, which is very rare in classical queueing models. Then we may consider input streams with general interarrival time distributions and servers with general service time distributions. Single server models may be easily incorporated into a network of queues. Here, we apply the diffusion approximation formalism to study transient behaviour of G / G / N / N station and use it to construct a model of a typical call centre and to study the sliding window mechanism, a popular Call Admission Control (CAC) algorithm. "
}

%25
@article{Kloul2009145,
title = "Performance Analysis of a Software Retrieval Service ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "232",
number = "0",
pages = "145 - 163",
year = "2009",
note = "Proceedings of the Third International Workshop on the Practical Application of Stochastic Modelling (PASM 2008) ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2009.02.055",
url = "http://www.sciencedirect.com/science/article/pii/S1571066109000607",
author = "Leïla Kloul",
keywords = "Distributed systems",
keywords = "Mobile components",
keywords = "Performance engineering",
keywords = "Stochastic process algebra",
keywords = "UML2.0 ",
abstract = "The work we present in this paper is based on an approach we have developed to model mobility and performance information at the design level. This approach consists in translating a UML2.0 model onto a process algebra, namely \{PEPA\} nets, model. Once the process algebra model generated, performance analysis of the modelled system can be carried out. In this paper, we show how to use this approach to investigate the performance of a software retrieval service. "
}

%26
@article{Brenner2009165,
title = "Modelling Grid5000 point availability with \{SAN\} ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "232",
number = "0",
pages = "165 - 178",
year = "2009",
note = "Proceedings of the Third International Workshop on the Practical Application of Stochastic Modelling (PASM 2008) ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2009.02.056",
url = "http://www.sciencedirect.com/science/article/pii/S1571066109000619",
author = "Leonardo Brenner and Paulo Fernandes and Jean-Michel Fourneau and Brigitte Plateau",
keywords = "Stochastic Automata Networks",
keywords = "grid computing",
keywords = "point availability ",
abstract = "The point availability is the probability that a system is available at time t. As grids need a lot of resources to be really operational, the evolution of their availability with time or depending on a maintenance process is a hot topic. But as grids contain a lot of resources, it is quite difficult to model and solve this problem. Here we advocate a component based description which is associated to a tensor based numerical approach. "
}

%--------------04th PASM

%27
@article{Wolter20105,
title = "Stochastic Models for Dependable Services ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "261",
number = "0",
pages = "5 - 21",
year = "2010",
note = "Proceedings of the Fourth International Workshop on the Practical Application of Stochastic Modelling (PASM 2009) ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2010.01.003",
url = "http://www.sciencedirect.com/science/article/pii/S1571066110000046",
author = "Katinka Wolter and Philipp Reinecke",
keywords = "Fault model",
keywords = "performance model",
keywords = "dependability",
keywords = "adaptivity ",
abstract = "In this paper we investigate the use of stochastic models for analysing service-oriented systems. We propose an iterative hybrid approach using system measurements, testbed observations as well as formal models to derive a quantitative model of service-based systems that allows us to evaluate the effectiveness of the restart method in such systems. In cases where one is fortunate enough as to have access to a real system for measurements the obtained data often is lacking statistical significance or knowledge of the system is not sufficient to explain the data. A testbed may then be preferable as it allows for long experiment series and provides full control of the system's configuration. In order to provide meaningful data the testbed must be equipped with fault-injection using a suitable fault-model and an appropriate load model. We fit phase-type distributions to the data obtained from the testbed in order to represent the observed data in a model that can be used e.g. as a service process in a queueing model of our service-oriented system. The queueing model may be used to analyse different restart policies, buffer size or service disciplines. Results from the model can be fed into the testbed and provide it with better fault and load models thus closing the modelling loop. "
}

%28
@article{Harrison201023,
title = "Modelling Interactive Experience, Function and Performance in Ubiquitous Systems ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "261",
number = "0",
pages = "23 - 42",
year = "2010",
note = "Proceedings of the Fourth International Workshop on the Practical Application of Stochastic Modelling (PASM 2009) ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2010.01.004",
url = "http://www.sciencedirect.com/science/article/pii/S1571066110000058",
author = "Michael D. Harrison and Mieke Massink",
keywords = "interactive systems",
keywords = "model checking",
keywords = "stochastic modelling",
keywords = "ubiquitous computing",
keywords = "human computer interaction ",
abstract = "The cost of deploying a ubiquitous system to enhance a physical environment is likely to be considerable. The success of its deployment is highly dependent on its context: the physical environment and the activities that are to be carried out within it. This paper provides an initial exploration of whether stochastic process algebras (in particular \{PEPA\} with a Fluid Flow semantics) might be used to explore consequences before deployment. The focus of the exploration is to aid understanding of how a proposed system supports users within the environment. The challenge is to provide notations and techniques that will enable the analysis of potentially complex systems. "
}

%29
@article{Ciocchetta201043,
title = "Bio-PEPA for Epidemiological Models ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "261",
number = "0",
pages = "43 - 69",
year = "2010",
note = "Proceedings of the Fourth International Workshop on the Practical Application of Stochastic Modelling (PASM 2009) ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2010.01.005",
url = "http://www.sciencedirect.com/science/article/pii/S157106611000006X",
author = "Federica Ciocchetta and Jane Hillston",
keywords = "Process algebra",
keywords = "epidemiological models",
keywords = "modelling",
keywords = "stochastic simulation",
keywords = "model checking",
keywords = "ordinary differential equations ",
abstract = "Many models have been defined in order to describe the evolution of a disease in a population. The modelling of diseases is helpful to understand the mechanisms for their spread and to predict their future evolution. Most of the models in the literature are defined in terms of systems of differential equations and only a few of them propose stochastic simulation for the analysis. The main aim of this work is to apply the process algebra Bio-PEPA for the modelling and analysis of epidemiological models. As Bio-PEPA has been originally defined for biochemical networks, we define a variant of it suitable for representing epidemiological models. Some features of Bio-PEPA are useful in the context of epidemiology as well: location can abstract spatial structure and event can describe the introduction of prophylaxis in a population infected by a disease at a given day. Concerning the analysis, we can take advantage of the various kinds of analysis supported by Bio-PEPA, such as, for instance, stochastic simulation, model checking and ODE-based analyses. In particular, the modeller can select the most appropriate approach for the study of the model and analysis techniques can be used together for a better understanding of the behaviour of the system. In this paper we apply Bio-PEPA to the study of epidemiological models of avian influenza, based on different assumptions about the spatial structure and the possible kind of treatment. These models demonstrate that Bio-PEPA has several features that facilitate epidemiological modelling. "
}

%30
@article{Slegers201071,
title = "A Langevin Interpretation of \{PEPA\} Models ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "261",
number = "0",
pages = "71 - 89",
year = "2010",
note = "Proceedings of the Fourth International Workshop on the Practical Application of Stochastic Modelling (PASM 2009) ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2010.01.006",
url = "http://www.sciencedirect.com/science/article/pii/S1571066110000071",
author = "Joris Slegers",
keywords = "Stochastic modelling",
keywords = "\{PEPA\}",
keywords = "stochastic differential equations ",
abstract = "In this paper we examine a Langevin interpretation of the stochastic process algebra PEPA. We show how previous work on chemical systems yielding sets of stochastic differential equations (SDEs) can be adapted to the domain of computer systems. Two simple examples are then examined. Their experimental results show a good match between traditional Markovian interpretation of \{PEPA\} and the \{SDE\} interpretation introduced here. It also raises the problem of boundary conditions which is briefly discussed and for which we propose a solution. "
}

%31
@article{Piazzolla201091,
title = "Analysis of Television and Cinema Productions using Mean Field Models ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "261",
number = "0",
pages = "91 - 108",
year = "2010",
note = "Proceedings of the Fourth International Workshop on the Practical Application of Stochastic Modelling (PASM 2009) ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2010.01.007",
url = "http://www.sciencedirect.com/science/article/pii/S1571066110000083",
author = "P. Piazzolla and M. Gribaudo",
keywords = "Mean field",
keywords = "Generalized Stochastic Petri Nets",
keywords = "Media Production",
keywords = "User Models ",
abstract = "Television and cinema productions have a critical influence in today's economy, but performance evaluation techniques are rarely used in these contexts. Both kind of productions share a similar key feature: the spectator. It is in fact the final user who determines the success of a production by deciding to spend his or her money for it. In this paper we use Mean Field techniques to model the behavior of the users, of the production and of the distribution. We use Generalized Stochastic Petri Nets as an upper level formalism to simplify the description of the proposed models. Finally we present comparisons with real data (where available) to prove the validity of the Mean Field approach. "
}

%32
@article{Schippers2010109,
title = "A Massively Scalable Architecture For Instant Messaging \& Presence ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "261",
number = "0",
pages = "109 - 130",
year = "2010",
note = "Proceedings of the Fourth International Workshop on the Practical Application of Stochastic Modelling (PASM 2009) ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2010.01.008",
url = "http://www.sciencedirect.com/science/article/pii/S1571066110000095",
author = "Jorrit Schippers and Anne Remke and Henk Punt and Maarten Wegdam and Boudewijn Haverkort",
keywords = "Instant Messaging and Presence Architecture",
keywords = "Queueing Models",
keywords = "Scalability ",
abstract = "This paper analyzes the scalability of Instant Messaging &amp; Presence (IM&amp;P) architectures. We take a queueing-based modelling and analysis approach to find the bottlenecks of the current IM&amp;P architecture at the Dutch social network Hyves, as well as to analyse three alternative architectures: evolutionary partitioning, aggregated, batched presence updates and presence subscriptions. We use the Hierarchical Evaluation Tool (HIT) to create and analyse models analytically. Based on these results, we recommend a new architecture that provides better scalability than the current one. "
}

%33
@article{SousaVieira2010131,
title = "Flexible adjustment of the short-term correlation of \{LRD\} M/G/∞-based processes ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "261",
number = "0",
pages = "131 - 145",
year = "2010",
note = "Proceedings of the Fourth International Workshop on the Practical Application of Stochastic Modelling (PASM 2009) ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2010.01.009",
url = "http://www.sciencedirect.com/science/article/pii/S1571066110000101",
author = "M.E. Sousa-Vieira and A. Suárez-González and R.F. Rodríguez-Rubio and C. López-García",
keywords = "Video traffic modeling",
keywords = "M/G/∞ process",
keywords = "Correlation",
keywords = "Synthetic efficient on-line generation ",
abstract = "Video represents a larger and larger portion of the traffic in Internet. This traffic is characterized by a high burstiness and a strong short- and long-range correlation, that is very important from the performance point of view. Particularly, the efficient generation of synthetic sample paths is fundamental because real traces are usually of limited length and lack the necessary diversity required to perform such analysis. In this paper, we focus on the M/G/∞ process due to its theoretical simplicity, its flexibility to exhibit both Short- and Long-Range Dependence and its advantages for simulation studies when compared to other types of processes, and we improve the adjustment of the short-term correlation of \{LRD\} M/G/∞-based processes adding autoregressive filters. "
}

%34
@article{Imre2010147,
title = "A Novel Cost Model of \{XML\} Serialization ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "261",
number = "0",
pages = "147 - 162",
year = "2010",
note = "Proceedings of the Fourth International Workshop on the Practical Application of Stochastic Modelling (PASM 2009) ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2010.01.010",
url = "http://www.sciencedirect.com/science/article/pii/S1571066110000113",
author = "G. Imre and M. Kaszó and T. Levendovszky and H. Charaf",
keywords = "Software performance",
keywords = "\{XML\} serialization",
keywords = "performance modeling ",
abstract = "Using \{XML\} as a data representation format is a common choice when integrating software systems on different platforms. The serialization of in-memory object instances of a class into corresponding \{XML\} documents heavily influences the performance of the XML-based communication, even if we send the \{XML\} over \{HTTP\} as in the case of SOAP-based \{XML\} Web Services, or with asynchronous messaging such as Java Message Service (JMS), or simply saving it into a file. Several studies have been published analyzing the performance impact of \{XML\} serialization on different platforms. No models or measurement methodologies have been proposed however, to establish a relationship between the serialization cost of primitive types (e.g. int, double, string), and the serialization cost of composite types. Such a model can be very useful when the type of the \{XML\} messages exchanged during the communication are known a priori, recorded in an interface definition, similarly to the Web Services Description Language (WSDL) in case of \{XML\} Web Services. This paper introduces a model that is validated with measurements on .NET and Java platform. The opposite direction, deserialization is covered as well. The main mathematical tool used is linear regression, but cases are also shown and explained where linearity is compromised. "
}

%35
@article{Dimitriadou2010163,
title = "Multi-Site Allocation Policies on a Grid and Local Level ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "261",
number = "0",
pages = "163 - 179",
year = "2010",
note = "Proceedings of the Fourth International Workshop on the Practical Application of Stochastic Modelling (PASM 2009) ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2010.01.011",
url = "http://www.sciencedirect.com/science/article/pii/S1571066110000125",
author = "Sofia K. Dimitriadou and Helen D. Karatza",
keywords = "Grid computing",
keywords = "gang scheduling",
keywords = "backfilling",
keywords = "job allocation ",
abstract = "Efficient job scheduling in computational grids is a challenging task, especially when the workload consists of jobs submitted in a grid and local level. In this study, we consider such a grid system where both local jobs and grid jobs require service. The goal is to maintain a balance between the two competitive job types, in order for every job to be executed in a timely manner. However, local jobs are of higher importance compared to the grid jobs and it is imperative that their waiting time be minimized. Grid jobs are parallel jobs so gang scheduling is implemented, along with various other scheduling techniques in order to improve performance, such as backfilling. A simulation model is considered to evaluate system performance, and experiments are conducted to determine which proposed scheduling policy provides the best results. "
}

%36
@article{PerezPalacin2010181,
title = "Performance Evaluation of Self-reconfigurable Service-oriented Software With Stochastic Petri Nets ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "261",
number = "0",
pages = "181 - 201",
year = "2010",
note = "Proceedings of the Fourth International Workshop on the Practical Application of Stochastic Modelling (PASM 2009) ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2010.01.012",
url = "http://www.sciencedirect.com/science/article/pii/S1571066110000137",
author = "Diego Perez-Palacin and José Merseguer",
abstract = "Open-world software is a paradigm which allows to develop distributed and heterogeneous software systems. They can be built by integrating already developed third-party services, which use to declare QoS values (e.g., related to performance). It is true that these QoS values are subject to some uncertainties. Consequently, the performance of the systems using these services may unexpectedly decrease. A challenge for this kind of software is to self-adapt its behavior as a response to changes in the availability or performance of the required services. In this paper, we develop an approach to model self-renconfigurable open-world software systems with stochastic Petri nets. Moreover, we develop strategies for a system to gain a new state where it can recover its availability or even improve its performance. Through an example, we apply these strategies and evaluate them to discover suitable reconfigurations for the system. Results will announce appropriate strategies for system performance enhancement. "
}

%--------------05th PASM

%37
@article{AlvesJr20115,
title = "Towards the Evaluation of Environment and Business Trade-offs in Supply Chains ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "275",
number = "0",
pages = "5 - 21",
year = "2011",
note = "Fifth International Workshop on the Practical Application of Stochastic Modelling (PASM) ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2011.09.002",
url = "http://www.sciencedirect.com/science/article/pii/S1571066111000934",
author = "Gabriel Alves Jr. and Paulo Maciel and Ricardo Lim and Fábio Magnani and Adilson Arcoverde Jr.",
keywords = "Key Environmental Indicators",
keywords = "Life Cycle Assessment",
keywords = "Manufacturing Systems",
keywords = "Modeling",
keywords = "Performance Evaluation",
keywords = "Stochastic Models",
keywords = "Supply Chains ",
abstract = "Supply chains (SCs) are one of the most environment impacting systems. Analysis of such systems should thus take into account not only performance but also environment indicators. The amount of energy consumed for producing goods and the total emissions of greenhouse gases (GHG) of an activity are examples of such indicators. This paper presents a framework for assessing performance as well as Global Warming Potential (GWP) and exergy indicators in SCs. In order, exergy accounting helps on finding reliable \{GWP\} indicators for different energy sources adopted in the supply chain. This framework supports the evaluation of supply chainsʼ business and environment indicators trade-offs using a unified model. A real case study is conducted to demonstrate the application of the proposed modeling technique. "
}

%38
@article{Angius201123,
title = "The Monte Carlo \{EM\} method for the parameter estimation of biological models ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "275",
number = "0",
pages = "23 - 36",
year = "2011",
note = "Fifth International Workshop on the Practical Application of Stochastic Modelling (PASM) ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2011.09.003",
url = "http://www.sciencedirect.com/science/article/pii/S1571066111000946",
author = "Alessio Angius and András Horváth",
keywords = "parameter estimation",
keywords = "mass action kinetics",
keywords = "maximum likelihood",
keywords = "expectation-maximisation method ",
abstract = "It is often the case in modeling biological phenomena that the structure and the effect of the involved interactions are known but the rates of the interactions are neither known nor can easily be determined by experiments. This paper deals with the estimation of the rate parameters of reaction networks in a general and abstract context. In particular, we consider the case in which the phenomenon under study is stochastic and a continuous-time Markov chain (CTMC) is appropriate for its modeling. Further, we assume that the evolution of the system under study cannot be observed continuously but only at discrete sampling points between which a large amount of reactions can occur. The parameter estimation of stochastic reaction networks is often performed by applying the principle of maximum likelihood. In this paper we describe how the Expectation-Maximisation (EM) method, which is a technique for maximum likelihood estimation in case of incomplete data, can be adopted to estimate kinetic rates of reaction networks. In particular, because of the huge state space of the underlying CTMC, it is convenient to use such a variant of the \{EM\} approach, namely the Monte Carlo \{EM\} (MCEM) method, which makes use of simulation for the analysis of the model. We show that in case of mass action kinetics the application of the \{MCEM\} method results in an efficient and surprisingly simple estimation procedure. We provide examples to illustrate the characteristics of the approach and show that it is applicable in case of systems of reactions involving several species. "
}

%39
@article{Barbierato201137,
title = "Defining Formalisms for Performance Evaluation With \{SIMTHESys\} ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "275",
number = "0",
pages = "37 - 51",
year = "2011",
note = "Fifth International Workshop on the Practical Application of Stochastic Modelling (PASM) ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2011.09.004",
url = "http://www.sciencedirect.com/science/article/pii/S1571066111000958",
author = "Enrico Barbierato and Marco Gribaudo and Mauro Iacono",
keywords = "Performance analysis",
keywords = "tools",
keywords = "specification",
keywords = "performability-oriented formalism ",
abstract = "Tools for the analysis and modeling of complex systems must be able to support the extensibility of formalisms, reusability of models and customization of formalism compositions. From this perspective, \{SIMTHESys\} (Structured Infrastructure for Multiformalism modeling and Testing of Heterogeneous formalisms and Extensions for SYStems) is a new approach to the specification of performability oriented formalisms and the evaluation of models. Its originality emerges from the explicit definition of both syntax and evolution semantics of the considered formalism elements. The solution of models is made possible by using a set of non-specialized solving engines used to generate automatically formalism-specific reusable solvers. This paper explains how formalisms can be created in \{SIMTHESys\} by showing how three widely known modeling languages are successfully implemented. "
}

%40
@article{Czekster201153,
title = "Stochastic Model for QoS Assessment in Multi-tier Web Services ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "275",
number = "0",
pages = "53 - 72",
year = "2011",
note = "Fifth International Workshop on the Practical Application of Stochastic Modelling (PASM) ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2011.09.005",
url = "http://www.sciencedirect.com/science/article/pii/S157106611100096X",
author = "Ricardo M. Czekster and Paulo Fernandes and Afonso Sales and Thais Webber and Avelino F. Zorzo",
keywords = "Analytical Modeling",
keywords = "Stochastic Automata Networks",
keywords = "Service Level Agreements",
keywords = "Quality of Service",
keywords = "Performance Evaluation ",
abstract = "Service Level Agreements (SLAs) are used to guarantee quality of service (QoS) between customers and service providers. In an SLA, parties establish a common set of rules and responsibilities. In this paper we propose a practical stochastic modeling of a multi-tier architecture considering \{SLAs\} for specific transactions. The model is parameterized with available performance testing data for a real web service, and with a testing environment having unpredictable and unknown external workloads of simultaneous execution. In addition, we present multiple scenarios of external applications impacting on the \{SLAs\} in our target architecture. Having a previous knowledge about the average time demanded by some external applications, our model results can provide evidences when the system under test will not respect the agreed-upon SLAs. Finally, we discuss possible model extensions towards further unknown workload characterizations and considerations about application execution profiling. "
}

%41
@article{Fernandes201173,
title = "Performance Evaluation of Software Development Teams: a Practical Case Study ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "275",
number = "0",
pages = "73 - 92",
year = "2011",
note = "Fifth International Workshop on the Practical Application of Stochastic Modelling (PASM) ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2011.09.006",
url = "http://www.sciencedirect.com/science/article/pii/S1571066111000971",
author = "Paulo Fernandes and Afonso Sales and Alan R. Santos and Thais Webber",
keywords = "Performance Evaluation",
keywords = "Analytical Modeling",
keywords = "Stochastic Automata Networks",
keywords = "Global Software Development",
keywords = "Team Building Process ",
abstract = "Software development projects have become a challenge for both industry and academia regarding the performance evaluation of teams. Recently, a Stochastic Automata Networks (SAN) model was proposed as theoretical representation for performance prediction of software development teams. In this paper, we present an exercise of such \{SAN\} analytical modeling for a practical case study from an Information Technology company that has multiple sites and different participantsʼ roles and expertises. We present the matching of our model predictions with the actual project observations. Then, we focus our attention on the central entity varying its availability and the level of provided support in order to observe the impact on the participantsʼ performance. We summarize our study with further discussions of numerical results and possible model extensions. "
}

%42
@article{Horng201193,
title = "LocTrackJINQS: An Extensible Location-aware Simulation Tool for Multiclass Queueing Networks ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "275",
number = "0",
pages = "93 - 104",
year = "2011",
note = "Fifth International Workshop on the Practical Application of Stochastic Modelling (PASM) ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2011.09.007",
url = "http://www.sciencedirect.com/science/article/pii/S1571066111000983",
author = "Tzu-Ching Horng and Nikolas Anastasiou and Tony Field and William Knottenbelt",
keywords = "Simulation",
keywords = "Queueing Network",
keywords = "Location Tracking ",
abstract = "This paper presents LocTrackJINQS, a flexible and extensible spatio-temporal simulation tool for systems that involve the flow and processing of customers at multiple service centres. Developed based on the multi-class queueing network simulation package JINQS, LocTrackJINQS retains the abstract model specification power of \{JINQS\} while providing additional low-level models of entity movement. Besides traditional performance metrics, LocTrackJINQS produces as output a trace of each entityʼs location in the system over time. It can thus be used to generate synthetic location tracking data for location-based research or applications. "
}

%43
@article{Leung2011105,
title = "Stochastic Modelling and Optimisation of Internet Auction Processes ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "275",
number = "0",
pages = "105 - 121",
year = "2011",
note = "Fifth International Workshop on the Practical Application of Stochastic Modelling (PASM) ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2011.09.008",
url = "http://www.sciencedirect.com/science/article/pii/S1571066111000995",
author = "Timothy L.Y. Leung and William J. Knottenbelt",
keywords = "Online Auctions",
keywords = "Internet Auctions",
keywords = "Auction Income",
keywords = "Auction Duration",
keywords = "Multiple Bids ",
abstract = "Internet auctions are an attractive mechanism for the exchange of goods at a non-fixed price point. The operation of these auctions can be run under a variety of parameters. In this paper, we provide a theoretical analysis of fixed time forward auctions in cases where a single bid or multiple bids are accepted in a single auction. A comparison of the economic benefits and the corresponding buyer and seller surpluses between the auctions where a single bid is accepted and the auctions where multiple bids are accepted is made. These models are verified through systematic simulation experiments, based on a series of operational assumptions, which characterise the arrival rate of bids, as well as the distribution from which the private values of buyers are sampled. Decision rules for optimising surplus under different auction fee structures are also given. "
}

%44
@article{Shoaib2011123,
title = "Web Application Performance Modeling Using Layered Queueing Networks ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "275",
number = "0",
pages = "123 - 142",
year = "2011",
note = "Fifth International Workshop on the Practical Application of Stochastic Modelling (PASM) ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2011.09.009",
url = "http://www.sciencedirect.com/science/article/pii/S1571066111001009",
author = "Yasir Shoaib and Olivia Das",
keywords = "Performance modeling and validation",
keywords = "Layered Queueing Networks",
keywords = "Software Performance Engineering",
keywords = "Performance measurement",
keywords = "Load Testing",
keywords = "\{PHP\} ",
abstract = "In this paper, a Layered Queueing Network (LQN) performance model is used for studying an Apache-PHP web application with PostgreSQL backend-database. Performance evaluation is done by obtaining load test measurements and by solving the \{LQN\} model. Model validation is performed by comparing the model results with the load test results. With average error of 3.77% for throughput and 12.15% for response times the model is shown to capture the web applicationʼs performance. Furthermore, performance analysis is done to determine the system configuration which would ease the identified bottleneck resource. "
}

%45
@article{Younes2011143,
title = "Analysis of the Expected Number of Hops in Mobile Ad Hoc Networks with Random Waypoint Mobility ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "275",
number = "0",
pages = "143 - 158",
year = "2011",
note = "Fifth International Workshop on the Practical Application of Stochastic Modelling (PASM) ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2011.09.010",
url = "http://www.sciencedirect.com/science/article/pii/S1571066111001010",
author = "Osama Younes and Nigel Thomas",
keywords = "Mobile Ad Hoc Networks",
keywords = "hop count",
keywords = "Random Waypoint Mobility",
keywords = "greedy routing ",
abstract = "The number of hops between the source and destination nodes is a key parameter in studying multi-hop ad hoc networks analytically. To the best of our known, there is no analytical work that considers the hop count of paths in \{MANETs\} in a random mobility environment. This paper presents a theoretical study for the expected number of hops between any random source-destination pair in multi-hop ad hoc networks where nodes move according to the random waypoint mobility model. The effects of network parameters such as node density, size of the network area, and node transmission range are studied. Simulation experiments for different network parameters have been conducted to validate the proposed analytical approach. "
}

%46
@article{Zeng2011159,
title = "Quantitative Evaluation of Enterprise \{DRM\} Technology ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "275",
number = "0",
pages = "159 - 174",
year = "2011",
note = "Fifth International Workshop on the Practical Application of Stochastic Modelling (PASM) ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2011.09.011",
url = "http://www.sciencedirect.com/science/article/pii/S1571066111001022",
author = "Wen Zeng and Aad van Moorsel",
keywords = "Petri-nets",
keywords = "stochastic modeling",
keywords = "\{DRM\} products",
keywords = "digital security",
keywords = "non-productive time",
keywords = "information help desk ",
abstract = "It is of critical business importance for organizations to keep confidential digital documents secure, as the potential cost and damage incurred from the loss of confidential digital documents have increased significantly in recent years. Digital Rights Management (DRM) was developed to help organizations keep digital documents secure, as one of many digital information security solutions. In this study, the functions of eight popular \{DRM\} products currently available on the market are reviewed, and the impact of using of these \{DRM\} products is evaluated quantitatively. A group of metrics is defined reflecting the potential costs and impact to the organization incurred by implementing \{DRM\} products. Stochastic models are used to quantitatively evaluate the costs and impact of implementing a particular \{DRM\} product. In this study, it is found that although \{DRM\} products protect digital assets by encryption and by providing central control on information within the organization, this comes at a cost, since these security mechanisms typically reduce the productivity of the staff. The reduction in productivity is in turn measured in the form of non-productive time (NPT) which is an inherent part of the stochastic modeling process. "
}

%--------------06th PASM

%47
@article{Amparore20137,
title = "Backward Solution of Markov Chains and Markov Regenerative Processes: Formalization and Applications ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "296",
number = "0",
pages = "7 - 26",
year = "2013",
note = "Proceedings the Sixth International Workshop on the Practical Application of Stochastic Modelling (PASM) and the Eleventh International Workshop on Parallel and Distributed Methods in Verification (PDMC). ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2013.07.002",
url = "http://www.sciencedirect.com/science/article/pii/S1571066113000339",
author = "Elvio G. Amparore and Susanna Donatelli",
keywords = "Stochastic Model Checking",
keywords = "Forward and Backward",
keywords = "Kolmogorov",
keywords = "\{MRP\} ",
abstract = "Abstract In this paper we investigate the computation, and the stochastic interpretation, of backward probabilities of Markov chains (transient and steady-state probabilities derived from backward Kolmogorov equations) and its extension to the case of Markov Regenerative Processes (MRP). The study is then extended to the case of non-ergodic settings, which enlights a substantial difference between the forward solution process (based on forward Kolmogorov equations) and the backward one. We shall clarify the role that backward solutions play in computing absorption probabilities and in the model-checking of stochastic logics as \{CSL\} and CSLTA, which typically require the steady state solution of a non-ergodic \{CTMC\} and \{MRP\} respectively. Moreover we show that the algorithm for the computation of the whole set of states that satisfy a \{CSL\} formula, which is standard practice in \{CSL\} model-checkers, can be seen as a case of computation of backward probabilities of Continuous Time Markov Chains (CTMCs). The backward computation of \{MRP\} is then inserted in the context of matrix-free solution technique, which allows to deal with \{MRP\} of much bigger size than the standard approach based on the computation and solution of the embedded Markov chain. "
}

%48
@article{Assunção201327,
title = "A Structured Stochastic Model for Prediction of Geological Stratal Stacking Patterns ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "296",
number = "0",
pages = "27 - 42",
year = "2013",
note = "Proceedings the Sixth International Workshop on the Practical Application of Stochastic Modelling (PASM) and the Eleventh International Workshop on Parallel and Distributed Methods in Verification (PDMC). ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2013.07.003",
url = "http://www.sciencedirect.com/science/article/pii/S1571066113000340",
author = "Joaquim Assunção and Luciana Espindola and Paulo Fernandes and Maria Pivel and Afonso Sales",
keywords = "Performance Evaluation",
keywords = "Analytical Modeling",
keywords = "Stochastic Automata Networks ",
abstract = "Abstract This article presents a novel Stochastic Automata Networks (SAN) model to estimate the behavior of sediment strata formation in continental margins resulting from interaction between sea level, sediment input and subsidence over the last 130 million years. The model result is a set of probabilities that can be compared with geological facts and hypothesis; thus, we can point out possible discrepancies from other similar works and also improve the chance of a good estimation of past geological events. "
}

%49
@article{Banks201343,
title = "Stochastic Modelling of the Kai-based Circadian Clock ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "296",
number = "0",
pages = "43 - 60",
year = "2013",
note = "Proceedings the Sixth International Workshop on the Practical Application of Stochastic Modelling (PASM) and the Eleventh International Workshop on Parallel and Distributed Methods in Verification (PDMC). ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2013.07.004",
url = "http://www.sciencedirect.com/science/article/pii/S1571066113000352",
author = "Chris Banks and Allan Clark and Anastasis Georgoulas and Stephen Gilmore and Jane Hillston and Dimitrios Milios and Ian Stark",
keywords = "Circadian",
keywords = "\{ODE\}",
keywords = "stochastic",
keywords = "temporal logic",
keywords = "Bio-PEPA",
keywords = "Continuous Pi ",
abstract = "Abstract We present two process algebra models of a Kai-protein based circadian clock. Our models are represented in the Bio-PEPA and the continuous pi-calculus process algebras. The circadian clock is not based on transcription and has been shown to persist with a rhythmic signal when removed from a living cell. Our models allow us to speculate as to the mechanisms which allow for the rhythmic signals. We reproduce previous results based on \{ODE\} models and then use our models as the basis for stochastic simulation. "
}

%50
@article{Barbierato201361,
title = "Exploiting product forms solution techniques in multiformalism modeling ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "296",
number = "0",
pages = "61 - 77",
year = "2013",
note = "Proceedings the Sixth International Workshop on the Practical Application of Stochastic Modelling (PASM) and the Eleventh International Workshop on Parallel and Distributed Methods in Verification (PDMC). ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2013.07.005",
url = "http://www.sciencedirect.com/science/article/pii/S1571066113000364",
author = "Enrico Barbierato and Gian-Luca Dei Rossi and Marco Gribaudo and Mauro Iacono and Andrea Marin",
keywords = "Multiformalism modeling",
keywords = "product-form solution",
keywords = "compositionality",
keywords = "performance evaluation ",
abstract = "Abstract Multiformalism modeling has shown to be a valuable technique to cope with the complexity of the constraints that apply to specifications of computer-based systems state of the art. Multiformalism techniques help modelers and designers by providing a more (natural and) convenient approach in the specification process and in analysis of performance. Although their application does not necessarily provide an advantage in the solutions of the models, this paper shows how a compositional multiformalism modeling approach can leverage the power of product-form solutions to offer both efficient solution and specification of models for complex systems. "
}

%51
@article{Barnat201379,
title = "Distributed \{LTL\} Model Checking with Hash Compaction ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "296",
number = "0",
pages = "79 - 93",
year = "2013",
note = "Proceedings the Sixth International Workshop on the Practical Application of Stochastic Modelling (PASM) and the Eleventh International Workshop on Parallel and Distributed Methods in Verification (PDMC). ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2013.07.006",
url = "http://www.sciencedirect.com/science/article/pii/S1571066113000376",
author = "J. Barnat and J. Havlíček and P. Ročkai",
keywords = "model checking",
keywords = "\{LTL\}",
keywords = "distributed",
keywords = "hash compaction",
keywords = "owcty ",
abstract = "Abstract We extend a distributed-memory explicit-state \{LTL\} model checking algorithm (OWCTY) with hash compaction. We provide a detailed description of the improved algorithm and a correctness argument in the theoretical part of the paper. Additionally, we deliver an implementation of the algorithm as part of out parallel and distributed-memory model checker DiVinE, and use this implementation for a practical evaluation of the approach, on which we report in the experimental part of the paper. "
}

%52
@article{vanderBerg201395,
title = "SpinS: Extending \{LTSmin\} with Promela through SpinJa ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "296",
number = "0",
pages = "95 - 105",
year = "2013",
note = "Proceedings the Sixth International Workshop on the Practical Application of Stochastic Modelling (PASM) and the Eleventh International Workshop on Parallel and Distributed Methods in Verification (PDMC). ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2013.07.007",
url = "http://www.sciencedirect.com/science/article/pii/S1571066113000388",
author = "Freark van der Berg and Alfons Laarman",
keywords = "model checking",
keywords = "Spin",
keywords = "\{LTSmin\}",
keywords = "SpinJa",
keywords = "Promela",
keywords = "multi-core",
keywords = "\{LTL\}",
keywords = "state compression",
keywords = "symbolic",
keywords = "decision diagram",
keywords = "distributed",
keywords = "partial order reduction ",
abstract = "Abstract We show how Promela can be supported by the high-performance generic model checker LTSmin. The success of the Spin model checker has made Promela an important modeling language. SpinJa was created as a Java implementation of Spin, in an effort to make the model checker easily extendible and reusable while maintaining some of its efficiency. While these goals were certainly met, the downside of SpinJa remained its dependability on Java, degrading performance by a factor 5 and obstructing support for embedded C code in Promela models. \{LTSmin\} aims at language-independence through the definition of the generic Partitioned Next-State Interface (pins). The toolset has shown that a generic model checker can indeed be competitive in terms of efficiency by supporting several languages from different paradigms and implementing many analysis algorithms that compete with other state-of-the-art model checkers. We extended SpinJa to emit C code that implements the pins interface. Our new version of SpinJa, called SpinS (Spin + pins), also improves Promela support, greatly extending the support of models beyond toy and academic examples. In this paper, we demonstrate the usage of LTSminʼs analysis algorithms: multi-core model checking of assertion violations, deadlocks and never claims (full LTL), inspection of error trails, partial order reduction (POR), state compression, symbolic reachability using (multi-core) decision diagrams and distributed reachability. Our experiments show that the performance of these methods beats other leading model checkers. "
}

%53
@article{Clark2013107,
title = "Conservation of Mass Analysis for Bio-PEPA ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "296",
number = "0",
pages = "107 - 126",
year = "2013",
note = "Proceedings the Sixth International Workshop on the Practical Application of Stochastic Modelling (PASM) and the Eleventh International Workshop on Parallel and Distributed Methods in Verification (PDMC). ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2013.07.008",
url = "http://www.sciencedirect.com/science/article/pii/S157106611300039X",
author = "Allan Clark and Stephen Gilmore and Maria Luisa Guerriero and Jane Hillston",
keywords = "Bio-PEPA ",
abstract = "Abstract This paper describes a static analysis for Bio-PEPA models based on the notion of conservation of mass. Failure to obey the law of mass conservation can be an indication that there is an error in the model description. Here we focus on the use of invariant analysis to identify such potential flaws in models. We extend the basic technique to consider open models, in which it is possible to automatically ignore some causes of mass production or consumption that are unlikely to be errors. Our approach is an improvement on direct application of invariant analysis because it does not depend on a deep understanding of the model and prior expectations of the sets of components which should have conserved mass. We demonstrate the use of our technique on a published model from the literature and explain how our analysis can be used to uncover potential problems in the model description. Of course, not all models which fail to conserve mass are flawed. Nevertheless, this represents an important method of model verification which can be applied before the model itself is evaluated — since the analysis does not depend on accurate dynamics it can be undertaken early in the model development process, before the model has been fully parameterised. "
}

%54
@article{vanDijk2013127,
title = "Multi-Core \{BDD\} Operations for Symbolic Reachability ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "296",
number = "0",
pages = "127 - 143",
year = "2013",
note = "Proceedings the Sixth International Workshop on the Practical Application of Stochastic Modelling (PASM) and the Eleventh International Workshop on Parallel and Distributed Methods in Verification (PDMC). ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2013.07.009",
url = "http://www.sciencedirect.com/science/article/pii/S1571066113000406",
author = "Tom van Dijk and Alfons Laarman and Jaco van de Pol",
keywords = "multi-core",
keywords = "\{BDD\}",
keywords = "symbolic reachability",
keywords = "parallel model checking",
keywords = "lockless hashtable",
keywords = "garbage collection",
keywords = "\{LTSmin\}",
keywords = "\{WOOL\}",
keywords = "Sylvan ",
abstract = "Abstract This paper presents scalable parallel \{BDD\} operations for modern multi-core hardware. We aim at increasing the performance of reachability analysis in the context of model checking. Existing approaches focus on performing multiple independent \{BDD\} operations rather than parallelizing the \{BDD\} operations themselves. In the past, attempts at parallelizing \{BDD\} operations have been unsuccessful due to communication costs in shared memory. We solved this problem by extending an existing lockless hashtable to support \{BDDs\} and garbage collection and by implementing a lockless memoization table. Using these lockless hashtables and the work-stealing framework Wool, we implemented a multi-core \{BDD\} package called Sylvan. We provide the experimental results of using this multi-core \{BDD\} package in the framework of the model checker LTSmin. We measured the runtime of the reachability algorithm on several models from the \{BEEM\} model database on a 48-core machine, demonstrating speedups of over 30 for some models, which is a breakthrough compared to earlier work. In addition, we improved the standard symbolic reachability algorithm to use a modified \{BDD\} operation that calculates the relational product and the variable substitution in one step. We show that this new algorithm improves the performance of symbolic reachability and decreases the memory requirements by up to 40%. "
}

%55
@article{Garavel2013145,
title = "Large-scale Distributed Verification Using CADP: Beyond Clusters to Grids ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "296",
number = "0",
pages = "145 - 161",
year = "2013",
note = "Proceedings the Sixth International Workshop on the Practical Application of Stochastic Modelling (PASM) and the Eleventh International Workshop on Parallel and Distributed Methods in Verification (PDMC). ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2013.07.010",
url = "http://www.sciencedirect.com/science/article/pii/S1571066113000418",
author = "Hubert Garavel and Radu Mateescu and Wendelin Serwe",
keywords = "asynchronous systems",
keywords = "distributed verification",
keywords = "labeled transition system",
keywords = "model checking",
keywords = "on-the-fly verification",
keywords = "process calculus ",
abstract = "Abstract Distributed verification uses the resources of several computers to speed up the verification and, even more importantly, to access large amounts of memory beyond the capabilities of a single computer. In this paper, we describe the distributed verification tools provided by the \{CADP\} (Construction and Analysis of Distributed Processes) toolbox, especially focusing on its most recent tools for management, inspection, and on-the-fly exploration of distributed state spaces. We also report about large-scale experiments carried out using these tools on Gridʼ5000 using up to 512 distributed processes. "
}

%56
@article{Markovski2013163,
title = "Extending a Synthesis-Centric Model-Based Systems Engineering Framework with Stochastic Model Checking ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "296",
number = "0",
pages = "163 - 181",
year = "2013",
note = "Proceedings the Sixth International Workshop on the Practical Application of Stochastic Modelling (PASM) and the Eleventh International Workshop on Parallel and Distributed Methods in Verification (PDMC). ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2013.07.011",
url = "http://www.sciencedirect.com/science/article/pii/S157106611300042X",
author = "J. Markovski and E.S. Estens Musa and M.A. Reniers",
keywords = "supervisory control theory",
keywords = "performance evaluation",
keywords = "Markov processes ",
abstract = "Abstract We propose to integrate performance evaluation with supervisory control synthesis to bring higher confidence in the control design. Supervisory control theory deals with automatic synthesis of supervisory controllers that ensure safe behavior of the supervised system, based on the models of the uncontrolled system and the (safety) control requirements. For the purpose of performance evaluation, we turn to stochastic model checking of continuous-time Markov chains, which requires an extension of the model of the uncontrolled system with Markovian delays. We cast our proposal as an extension of a model-based systems engineering framework that relies on supervisor synthesis. We treat the Markovian delays syntactically, exploiting their equivalent interleaving behavior with uniquely-named uncontrollable transitions. In this way, we can employ already available synthesis tools, while preserving the stochastic behavior. To this end, we develop model transformation tools to extract the underlying Markov process from the stochastic discrete-event model of the supervised system. We illustrate the approach by modeling a pipeless plant that employs automated guided vehicles instead of fixed piping in order to ensure greater flexibility of the plant. The control problem that we solve is safe high-level movement coordination of the vehicles, ensured by the supervisory controller. We show how to seamlessly introduce stochastic behavior in the supervised system and we evaluate several performance and reliability aspects of the plant. We implement the framework by interfacing two state-of-the-art tools: Supremica for supervisory controller synthesis and \{MRMC\} for Markovian model checking. To this end, we improve previous attempts by providing support for data-based observers, which greatly improve the modeling capabilities of the framework. "
}

%57
@article{Milios2013183,
title = "Markov Chain Simulation with Fewer Random Samples ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "296",
number = "0",
pages = "183 - 197",
year = "2013",
note = "Proceedings the Sixth International Workshop on the Practical Application of Stochastic Modelling (PASM) and the Eleventh International Workshop on Parallel and Distributed Methods in Verification (PDMC). ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2013.07.012",
url = "http://www.sciencedirect.com/science/article/pii/S1571066113000431",
author = "Dimitrios Milios and Stephen Gilmore",
keywords = "Markov chain",
keywords = "simulation",
keywords = "trajectory",
keywords = "random variable ",
abstract = "Abstract We propose an accelerated \{CTMC\} simulation method that is exact in the sense that it produces all of the transitions involved. We call our method Trajectory Sampling Simulation as it samples from the distribution of state sequences and the distribution of time given some particular sequence. Sampling from the trajectory space rather than the transition space means that we need to generate fewer random numbers, which is an operation that is typically computationally expensive. Sampling from the time distribution involves approximating the exponential distributions that govern the sojourn times with a geometric distribution. A proper selection for the approximation parameters can ensure that the stochastic process simulated is almost identical to the simulation of the original Markov chain. Our approach does not depend on the properties of the system and it can be used as an alternative to more efficient approaches when those are not applicable. "
}

%58
@article{Aidarov2013199,
title = "Energy-aware Management of Customer Streams ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "296",
number = "0",
pages = "199 - 210",
year = "2013",
note = "Proceedings the Sixth International Workshop on the Practical Application of Stochastic Modelling (PASM) and the Eleventh International Workshop on Parallel and Distributed Methods in Verification (PDMC). ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2013.07.013",
url = "http://www.sciencedirect.com/science/article/pii/S1571066113000443",
author = "K. Aidarov and P. Ezhilchelvan and I. Mitrani",
keywords = "QoS requirements",
keywords = "quality of service ",
abstract = "Abstract Customers submit streams of jobs of different types for execution at a service center. The number of jobs in each stream and the rate of their submission are specified. A service level agreement indicates the charge paid by the customer, the quality of service promised by the provider and the penalty to be paid by the latter if the QoS requirement is not met. To save energy, servers may be powered up and down dynamically. The objective is to maximize the revenues received while minimizing the penalties paid and the energy consumption costs of the servers used. To that end, heuristic policies are proposed for making decisions about stream admissions and server activation and deactivation. Those policies are motivated by queueing models. The results of several simulation experiments are described. "
}

%59
@article{Scott2013211,
title = "PEPAʼd Oysters: Converting Dynamic Energy Budget Models to Bio-PEPA, Illustrated by a Pacific Oyster Case Study ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "296",
number = "0",
pages = "211 - 228",
year = "2013",
note = "Proceedings the Sixth International Workshop on the Practical Application of Stochastic Modelling (PASM) and the Eleventh International Workshop on Parallel and Distributed Methods in Verification (PDMC). ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2013.07.014",
url = "http://www.sciencedirect.com/science/article/pii/S1571066113000455",
author = "Erin Scott and Andrew Hoyle and Carron Shankland",
keywords = "Dynamic Energy Budget Model",
keywords = "Bio-PEPA",
keywords = "Process Algebra",
keywords = "Pacific oyster (Crassostrea gigas) case study",
keywords = "Physiological models",
keywords = "Computational tools ",
abstract = "Abstract We present a Bio-PEPA (Biochemical-Performance Evaluation Process Algebra) computational model for the Pacific oyster, derived from a \{DEB\} (Dynamic Energy Budget) mathematical model. Experience with this specific model allows us to propose a generic scheme for translation between the widely-used \{DEB\} theory and Bio-PEPA. The benefits of translation are that a range of novel analysis tools become available, therefore improving the potential to understand complex biological phenomena at a systems level. This work also provides a link between biology, mathematics and computer science: such interlinking of disciplines is the core of the systems approach to biology. "
}

%60
@article{Tarasyuk2013229,
title = "Discrete Time Stochastic Petri Box Calculus with Immediate Multiactions dtsiPBC ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "296",
number = "0",
pages = "229 - 252",
year = "2013",
note = "Proceedings the Sixth International Workshop on the Practical Application of Stochastic Modelling (PASM) and the Eleventh International Workshop on Parallel and Distributed Methods in Verification (PDMC). ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2013.07.015",
url = "http://www.sciencedirect.com/science/article/pii/S1571066113000467",
author = "Igor V. Tarasyuk and Hermenegilda Macià and Valentín Valero",
keywords = "Stochastic process algebra",
keywords = "Petri box calculus",
keywords = "discrete time",
keywords = "immediate multiaction",
keywords = "probabilistic transition system",
keywords = "\{LDTSIPN\}",
keywords = "performance evaluation",
keywords = "shared memory system ",
abstract = "Abstract We propose discrete time stochastic Petri box calculus extended with immediate multiactions, called dt-siPBC. The step operational semantics is constructed via labeled probabilistic transition systems. The denotational semantics is defined via labeled discrete time stochastic Petri nets with immediate transitions (LDTSIPNs). A consistency of both semantics is demonstrated. In order to evaluate performance, the corresponding semi-Markov chains are analyzed. In a case study, performance of the shared memory system is evaluated. "
}

%61
@article{Kähkönen2013253,
title = "LCT: A Parallel Distributed Testing Tool for Multithreaded Java Programs ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "296",
number = "0",
pages = "253 - 259",
year = "2013",
note = "Proceedings the Sixth International Workshop on the Practical Application of Stochastic Modelling (PASM) and the Eleventh International Workshop on Parallel and Distributed Methods in Verification (PDMC). ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2013.09.002",
url = "http://www.sciencedirect.com/science/article/pii/S1571066113000480",
author = "Kari Kähkönen and Olli Saarikivi and Keijo Heljanko",
keywords = "Concolic testing",
keywords = "distributed testing",
keywords = "symbolic execution ",
abstract = "Abstract \{LIME\} Concolic Tester (LCT) is an open source automated testing tool that allows testing both sequential and multithreaded Java programs. The tool uses concolic testing to handle input values and dynamic partial order reduction (DPOR) combined with sleep sets to avoid exploring unnecessary interleavings of threads. The \{LCT\} tool has been designed for distributed use where the \{SMT\} constraint solving and test execution can be distributed to multiple processes on a network of workstations. In this paper we describe the architecture behind the tool and how it allows distributing concolic testing with \{DPOR\} and sleep set algorithms. This allows different execution paths of a given program to be tested in parallel. We evaluate the architecture and distributed algorithms of the tool on several Java benchmark programs. "
}

%62
@article{Zhang2013261,
title = "Modeling and Evaluation of Wireless Sensor Network Protocols by Stochastic Timed Automata ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "296",
number = "0",
pages = "261 - 277",
year = "2013",
note = "Proceedings the Sixth International Workshop on the Practical Application of Stochastic Modelling (PASM) and the Eleventh International Workshop on Parallel and Distributed Methods in Verification (PDMC). ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2013.09.001",
url = "http://www.sciencedirect.com/science/article/pii/S1571066113000479",
author = "Fengling Zhang and Lei Bu and Linzhang Wang and Jianhua Zhao and Xin Chen and Tian Zhang and Xuandong Li",
keywords = "Wireless Sensor Network Protocol",
keywords = "Modeling and Evaluation",
keywords = "Stochastic Timed Automata",
keywords = "Statistical Model Checking ",
abstract = "Abstract Wireless Sensor Networks (WSNs) are widely used in different kinds of environments. They may encounter lots of stochastic uncertainties and disturbances like message loss and node dynamics. Thus, it is critical to ensure the correctness of low level protocols in \{WSNs\} and evaluate their performance under different circumstances. In this paper, we propose a new method to analyze and evaluate \{WSN\} protocols based on stochastic timed automata and statistical model checking. For modeling, the work flow of a \{WSN\} protocol can be modeled with classical timed automata. Then, to model the uncertainties such as message loss and node dynamics, which are common in realistic circumstances, the timed automata can be extended by stochastic transitions, resulting in the stochastic timed automata. For analysis, the correctness of the protocol can be answered by classical model checking on the timed automata, while the performance of the protocol under realistic environments can be evaluated by statistical model checking on the stochastic model. To illustrate the feasibility and scalability of the modeling and verification method presented in this paper, Timing-sync Protocol for Sensor Networks (TPSN) will be studied completely throughout the paper. "
}

%--------------07th PASM

%63
@article{Avritzer20155,
title = "Survivability Evaluation of Gas, Water and Electricity Infrastructures ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "310",
number = "0",
pages = "5 - 25",
year = "2015",
note = "Proceedings of the Seventh International Workshop on the Practical Application of Stochastic Modelling (PASM) ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2014.12.010",
url = "http://www.sciencedirect.com/science/article/pii/S1571066114000942",
author = "Alberto Avritzer and Laura Carnevali and Hamed Ghasemieh and Lucia Happe and Boudewijn R. Haverkort and Anne Koziolek and Daniel Menasche and Anne Remke and Sahra Sedigh Sarvestani and Enrico Vicario",
keywords = "Survivability",
keywords = "critical infrastructures",
keywords = "cyber-physical systems",
keywords = "gas distribution networks",
keywords = "water distribution networks",
keywords = "smart grids",
keywords = "hybrid models ",
abstract = "Abstract The infrastructures used in cities to supply power, water and gas are consistently becoming more automated. As society depends critically on these cyber-physical infrastructures, their survivability assessment deserves more attention. In this overview, we first touch upon a taxonomy on survivability of cyber-physical infrastructures, before we focus on three classes of infrastructures (gas, water and electricity) and discuss recent modelling and evaluation approaches and challenges. "
}

%64
@article{Bortolussi201527,
title = "Fluid Performability Analysis of Nested Automata Models ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "310",
number = "0",
pages = "27 - 47",
year = "2015",
note = "Proceedings of the Seventh International Workshop on the Practical Application of Stochastic Modelling (PASM) ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2014.12.011",
url = "http://www.sciencedirect.com/science/article/pii/S1571066114000954",
author = "Luca Bortolussi and Jane Hillston and Mirco Tribastone",
keywords = "Systems of systems",
keywords = "fluid approximation",
keywords = "software performance modelling ",
abstract = "Abstract In this paper we present a class of nested automata for the modelling of performance, availability, and reliability of software systems with hierarchical structure, which we call systems of systems. Quantitative modelling provides valuable insight into the dynamic behaviour of software systems, allowing non-functional properties such as performance, dependability and availability to be assessed. However, the complexity of many systems challenges the feasibility of this approach as the required mathematical models grow too large to afford computationally efficient solution. In recent years it has been found that in some cases a fluid, or mean field, approximation can provide very good estimates whilst dramatically reducing the computational cost. The systems of systems which we propose are hierarchically arranged automata in which influence may be exerted between siblings, between parents and children, and even from children to parents, allowing a wide range of complex dynamics to be captured. We show that, under mild conditions, systems of systems can be equipped with fluid approximation models which are several orders of magnitude more efficient to run than explicit state representations, whilst providing excellent estimates of performability measures. This is a significant extension of previous fluid approximation results, with valuable applications for software performance modelling. "
}

%65
@article{Cerotti201549,
title = "Asymptotic Behavior and Performance Constraints of Replication Policies ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "310",
number = "0",
pages = "49 - 63",
year = "2015",
note = "Proceedings of the Seventh International Workshop on the Practical Application of Stochastic Modelling (PASM) ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2014.12.012",
url = "http://www.sciencedirect.com/science/article/pii/S1571066114000966",
author = "Davide Cerotti and Marco Gribaudo and Pietro Piazzolla and Giuseppe Serazzi",
keywords = "Replication",
keywords = "Multiclass workload",
keywords = "Cloud computing and virtualization",
keywords = "Analytical techniques",
keywords = "Asymptotic techniques ",
abstract = "Abstract Spreading the workload among a pool of replicated servers is a technique typically adopted to reduce the response time and increase the throughput in complex systems. In several actual computing environments, virtual machines can be provisioned in a fast and convenient way, and the replication has assumed an important role for the efficient system management. However, in order to provide economically acceptable solutions, the number of replica should be limited to the minimum required to match the given performance goal. In this paper we propose a simple replication policy to match thresholds on the system response times. The analytical relationships that exist between the performance objective values of some metrics and the number of replica are derived. Analytical and experimental validations with single and multi-class workload are presented. Open and closed models, and NO-SQL database have been considered. "
}

%66
@article{Forshaw201565,
title = "Energy-efficient Checkpointing in High-throughput Cycle-stealing Distributed Systems ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "310",
number = "0",
pages = "65 - 90",
year = "2015",
note = "Proceedings of the Seventh International Workshop on the Practical Application of Stochastic Modelling (PASM) ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2014.12.013",
url = "http://www.sciencedirect.com/science/article/pii/S1571066114000978",
author = "Matthew Forshaw and A. Stephen McGough and Nigel Thomas",
keywords = "Energy efficiency",
keywords = "Checkpointing",
keywords = "Migration",
keywords = "Fault tolerance",
keywords = "Desktop Grids ",
abstract = "Abstract Checkpointing is a fault-tolerance mechanism commonly used in High Throughput Computing (HTC) environments to allow the execution of long-running computational tasks on compute resources subject to hardware or software failures as well as interruptions from resource owners and more important tasks. Until recently many researchers have focused on the performance gains achieved through checkpointing, but now with growing scrutiny of the energy consumption of \{IT\} infrastructures it is increasingly important to understand the energy impact of checkpointing within an \{HTC\} environment. In this paper we demonstrate through trace-driven simulation of real-world datasets that existing checkpointing strategies are inadequate at maintaining an acceptable level of energy consumption whilst maintaing the performance gains expected with checkpointing. Furthermore, we identify factors important in deciding whether to exploit checkpointing within an \{HTC\} environment, and propose novel strategies to curtail the energy consumption of checkpointing approaches whist maintaining the performance benefits. "
}

%67
@article{Gribaudo201591,
title = "Exploiting Bayesian Networks for the Analysis of Combined Attack Trees ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "310",
number = "0",
pages = "91 - 111",
year = "2015",
note = "Proceedings of the Seventh International Workshop on the Practical Application of Stochastic Modelling (PASM) ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2014.12.014",
url = "http://www.sciencedirect.com/science/article/pii/S157106611400098X",
author = "Marco Gribaudo and Mauro Iacono and Stefano Marrone",
keywords = "Attack Trees",
keywords = "Quantitative Risk Assessement",
keywords = "Bayesian Networks",
keywords = "Model Transformations ",
abstract = "Abstract The growing need to find proper countermeasures able to protect critical infrastructures from threats has addressed the definition of quantitative methodologies for risk assessment. One of the most difficult aspects in this topic is the evaluation of the effects of attacks. Attacks Trees represent one of the most used formalisms in the modeling of attack scenarios: notwithstanding some extensions have been proposed to enrich the expressiveness of the original formalism, some effort should be spent on their analyzability. This paper defines a transformational approach that translates Attack Trees into Bayesian Networks. The proposed approach can cope with different Attack Trees extensions; moreover, it allows the quantitative evaluation of combined attacks modelled as a set of Attack Trees. "
}

%68
@article{Montecchi2015113,
title = "Model-based Evaluation of Scalability and Security Tradeoffs: a Case Study on a Multi-Service Platform ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "310",
number = "0",
pages = "113 - 133",
year = "2015",
note = "Proceedings of the Seventh International Workshop on the Practical Application of Stochastic Modelling (PASM) ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2014.12.015",
url = "http://www.sciencedirect.com/science/article/pii/S1571066114000991",
author = "Leonardo Montecchi and Nicola Nostro and Andrea Ceccarelli and Giuseppe Vella and Antonio Caruso and Andrea Bondavalli",
keywords = "Performance evaluation",
keywords = "scalability",
keywords = "web-services",
keywords = "security evaluation",
keywords = "security tradeoffs ",
abstract = "Abstract Current \{ICT\} infrastructures are characterized by increasing requirements of reliability, security, performance, availability, adaptability. A relevant issue is represented by the scalability of the system with respect to the increasing number of users and applications, thus requiring a careful dimensioning of resources. Furthermore, new security issues to be faced arise from exposing applications and data to the Internet, thus requiring an attentive analysis of potential threats and the identification of stronger security mechanisms to be implemented, which may produce a negative impact on system performance and scalability properties. The paper presents a model-based evaluation of scalability and security tradeoffs of a multi-service web-based platform, by evaluating how the introduction of security mechanisms may lead to a degradation of performance properties. The evaluation focuses on the \{OPENNESS\} platform, a web-based platform providing different kind of services, to different categories of users. The evaluation aims at identifying the bottlenecks of the system, under different configurations, and assess the impact of security countermeasures which were identified by a thorough threat analysis activity previously carried out on the target system. The modeling activity has been carried out using the Stochastic Activity Networks (SANs) formalism, making full use of its characteristics of modularity and reusability. The analysis model is realized through the composition of a set of predefined template models, which facilitates the construction of the overall system model, and the evaluation of different configuration by composing them in different ways. "
}

%69
@article{Polansky2015135,
title = "Obtaining Optimal Thresholds for Processors with Speed-Scaling ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "310",
number = "0",
pages = "135 - 155",
year = "2015",
note = "Proceedings of the Seventh International Workshop on the Practical Application of Stochastic Modelling (PASM) ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2014.12.016",
url = "http://www.sciencedirect.com/science/article/pii/S1571066114001005",
author = "Ronny J. Polansky and Samyukta Sethuraman and Natarajan Gautam",
keywords = "server speed-scaling",
keywords = "data center",
keywords = "power management",
keywords = "quality of service",
keywords = "fluid model",
keywords = "spectral expansion ",
abstract = "Abstract In this research we consider a processor that can operate at multiple speeds and suggest a strategy for optimal speed-scaling. While higher speeds improve latency, they also draw a lot of power. Thus we adopt a threshold-based policy that uses higher speeds under higher workload conditions, and vice versa. However, it is unclear how to select “optimal” thresholds. For that we use a stochastic fluid-flow model with varying processing speeds based on fluid level. First, given a set of thresholds, we develop an approach based on spectral expansion by modeling the evolution of the fluid queue as a semi-Markov process (SMP) and analyzing its performance. While there are techniques based on matrix-analytic methods and forward-backward decomposition, we show that they are not nearly as fast as the spectral-expansion SMP-based approach. Using the performance measures obtained from the \{SMP\} model, we suggest an algorithm for selecting the thresholds so that power consumption is minimized, while satisfying a quality-of-service constraint. We illustrate our results using a numerical example. "
}

%70
@article{Reijsbergen2015157,
title = "Patch-based Modelling of City-centre Bus Movement with Phase-type Distributions ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "310",
number = "0",
pages = "157 - 177",
year = "2015",
note = "Proceedings of the Seventh International Workshop on the Practical Application of Stochastic Modelling (PASM) ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2014.12.017",
url = "http://www.sciencedirect.com/science/article/pii/S1571066114001017",
author = "Daniël Reijsbergen and Stephen Gilmore and Jane Hillston",
keywords = "Public transportation",
keywords = "phase-type fitting",
keywords = "model checking ",
abstract = "Abstract We propose a methodology for constructing a stochastic performance model of a public transportation network using real-world data. Our main data source consists of Automatic Vehicle Location (AVL) measurements of buses in the Edinburgh region. Although the data has a relatively low frequency, we can use it to parameterise a model in which a bus moves between predefined patches in the city. We fit the probability distributions of the sojourn times in the patches to phase-type distributions using the tool HyperStar. We then translate the output from HyperStar to a model of a complete part of a bus route expressed in the reactive modules language of the \{PRISM\} model checker. Finally, we demonstrate how we can use the numerical techniques implemented in \{PRISM\} to answer meaningful questions about the performance of the bus network in the context of a case study involving the addition of trams to a busy section of Edinburgh's city centre. "
}

%71
@article{Vissat2015179,
title = "Finding Optimal Timetables for Edinburgh Bus Routes ",
journal = "Electronic Notes in Theoretical Computer Science ",
volume = "310",
number = "0",
pages = "179 - 199",
year = "2015",
note = "Proceedings of the Seventh International Workshop on the Practical Application of Stochastic Modelling (PASM) ",
issn = "1571-0661",
doi = "http://dx.doi.org/10.1016/j.entcs.2014.12.018",
url = "http://www.sciencedirect.com/science/article/pii/S1571066114001029",
author = "Ludovica Luisa Vissat and Allan Clark and Stephen Gilmore",
keywords = "Open data",
keywords = "parameter fitting",
keywords = "phase-type distributions",
keywords = "simulation",
keywords = "model-checking",
keywords = "optimisation ",
abstract = "Abstract We present a novel application of stochastic simulation and model-checking methods to determining whether bus services are fulfilling their service-level agreement to provide on-time departures of buses from stops sufficiently often. We use open data on predicted bus arrival times to parameterise a stochastic model of a particular bus route from Edinburgh city centre out to suburban and rural areas to the south of the city. We validate and then analyse our stochastic model using both simulation and model-checking methods. Finally, we complete an optimisation study on the model and discover a better timetable for the service which would expose the bus service operator to less financial risk of penalties being applied by the regulatory authorities which define standards for bus service, punctuality and reliability. "
}

%--------------08th PASM

%72
@article{BARBIERATO20165,
title = {Modeling Hybrid Systems in SIMTHESys},
journal = {Electronic Notes in Theoretical Computer Science},
volume = {327},
pages = {5-25},
year = {2016},
note = {The 8th International Workshop on Practical Application of Stochastic Modeling, PASM 2016},
issn = {1571-0661},
doi = {https://doi.org/10.1016/j.entcs.2016.09.021},
url = {https://www.sciencedirect.com/science/article/pii/S1571066116300664},
author = {Enrico Barbierato and Marco Gribaudo and Mauro Iacono},
keywords = {Performance evaluation, hybrid systems, metamodeling},
abstract = {Hybrid systems (HS) have been proven a valid formalism to study and analyze specific issues in a variety of fields. However, most of the analysis techniques for HS are based on low-level description, where single states of the systems have to be defined and enumerated by the modeler. Some high level modeling formalisms, such as Fluid Stochastic Petri Nets, have been introduced to overcome such difficulties, but simple procedures allowing the definitions of domain specific languages for HS could simplify the analysis of such systems. This paper presents a stochastic HS language consisting of a subset of piecewise deterministic Markov processes, and shows how SIMTHESys – a compositional, metamodeling based framework describing and extending formalisms – can be used to convert into this paradigm a wide number of high-level HS description languages. A simple example applying the technique to solve a model of the energy consumption of a data-center specified using Queuing Network and Hybrid Petri Nets is presented to show the effectiveness of the proposal.}
}

%73
@article{FOURNEAU201627,
title = {Dynamic Fault Trees with Rejuvenation: Numerical Analysis and Stochastic Bounds},
journal = {Electronic Notes in Theoretical Computer Science},
volume = {327},
pages = {27-47},
year = {2016},
note = {The 8th International Workshop on Practical Application of Stochastic Modeling, PASM 2016},
issn = {1571-0661},
doi = {https://doi.org/10.1016/j.entcs.2016.09.022},
url = {https://www.sciencedirect.com/science/article/pii/S1571066116300676},
author = {Jean-Michel Fourneau and Nihal Pekergin},
keywords = {Fault Trees, Stochastic Bounds, Maintenance, Rejuvenation, Discrete Distributions},
abstract = {This paper presents an extension of a methodology that we have introduced recently to analyze Dynamic Fault Trees (DFT). The failure time distributions of the components are obtained from measurements leading to discrete failure time distributions. The gate outputs in a DFT are numerically analyzed from the input failure time distributions. This paper presents one major extension in which maintenance operations are considered such that some components are replaced by new ones to increase the availability of the system.}
}

%74
@article{HAAR201649,
title = {Forecasting Passenger Loads in Transportation Networks},
journal = {Electronic Notes in Theoretical Computer Science},
volume = {327},
pages = {49-69},
year = {2016},
note = {The 8th International Workshop on Practical Application of Stochastic Modeling, PASM 2016},
issn = {1571-0661},
doi = {https://doi.org/10.1016/j.entcs.2016.09.023},
url = {https://www.sciencedirect.com/science/article/pii/S1571066116300688},
author = {Stefan Haar and Simon Theissing},
keywords = {Stochastic hybrid automata, Transportation networks, Fokker-Planck Equation},
abstract = {This work is part of an ongoing effort to understand the dynamics of passenger loads in modern, multimodal transportation networks (TNs) and to mitigate the impact of perturbations. The challenge is that the percentage of passengers at any given point of the TN that have a certain destination, i.e. their distribution over different trip profiles, is unknown. We introduce a stochastic hybrid automaton model for multimodal TNs that allows to compute how such probabilistic load vectors are propagated through the TN, and develop a computation strategy for forecasting the network's load a certain time into the future.}
}

%75
@article{MULLER201671,
title = {Enabling Fluid Analysis for Queueing Petri Nets via Model Transformation},
journal = {Electronic Notes in Theoretical Computer Science},
volume = {327},
pages = {71-91},
year = {2016},
note = {The 8th International Workshop on Practical Application of Stochastic Modeling, PASM 2016},
issn = {1571-0661},
doi = {https://doi.org/10.1016/j.entcs.2016.09.024},
url = {https://www.sciencedirect.com/science/article/pii/S157106611630069X},
author = {Christoph Müller and Piotr Rygielski and Simon Spinner and Samuel Kounev},
keywords = {Queueing Petri Nets, Layered Queueing Networks, Model Transformation, Fluid Analysis},
abstract = {Due to the growing size of modern IT systems, their performance analysis becomes an even more challenging task. Existing simulators are unable to analyze the behavior of large systems in a reasonable time, whereas analytical methods suffer from the state space explosion problem. Fluid analysis techniques can be used to approximate the solution of high-order Markov chain models enabling time efficient analysis of large performance models. In this paper, we describe a model-to-model transformation from queueing Petri nets (QPN) into layered queueing networks (LQN). Obtained LQN models can benefit from three existing solvers: LINE, LQNS, LQSIM. LINE internally utilize fluid limits approximation to speed up the solving process for large models. We present the incentives for developing the automated model-to-model transformation and present a systematic approach that we followed in its design. We demonstrate the transformations using representative examples. Finally, we evaluate and compare the performance predictions of existing analytical, simulation and fluid analysis solvers. We analyze solvers' limitations, solving time, and memory consumption.}
}

%76
@article{PERUMALLA201693,
title = {Model-based Dynamic Control of Speculative Forays in Parallel Computation},
journal = {Electronic Notes in Theoretical Computer Science},
volume = {327},
pages = {93-107},
year = {2016},
note = {The 8th International Workshop on Practical Application of Stochastic Modeling, PASM 2016},
issn = {1571-0661},
doi = {https://doi.org/10.1016/j.entcs.2016.09.025},
url = {https://www.sciencedirect.com/science/article/pii/S1571066116300706},
author = {Kalyan S. Perumalla and Mohammed M. Olama and Srikanth B. Yoginath},
keywords = {Reversible execution, Parallel Computing, Speculative Execution, Model-based Execution},
abstract = {In simulations running in parallel, the processors would have to synchronize with other processors to maintain correct global order of computations. This can be done either by blocking computation until correct order is guaranteed, or by speculatively proceeding with the best guess (based on local information) and later correcting errors if/as necessary. Since the gainful lengths of speculative forays depend on the dynamics of the application software and hardware at runtime, an online control system is necessary to dynamically choose and/or switch between the blocking and speculative strategies. In this paper, we formulate the reversible speculative computing in large-scale parallel computing as a dynamic linear feedback control (optimization) system model and evaluate its performance in terms of time and cost savings as compared to the traditional (forward) computing. We illustrate with an exact analogy in the form of vehicular travel under dynamic, delayed route information. The objective is to assist in making the optimal decision on what computational approach is to be chosen, by predicting the amount of time and cost savings (or losing) under different environments represented by different parameters and probability distribution functions. We consider the cases of Gaussian, exponential and log-normal distribution functions. The control system is intended for incorporating into speculative parallel applications such as optimistic parallel discrete event simulations to decide at runtime when and to what extent speculative execution can be performed gainfully.}
}

%77
@article{TODINOV2016109,
title = {Stochastic Pruning and Its Application for Fast Estimation of the Expected Total Output of Complex Systems},
journal = {Electronic Notes in Theoretical Computer Science},
volume = {327},
pages = {109-123},
year = {2016},
note = {The 8th International Workshop on Practical Application of Stochastic Modeling, PASM 2016},
issn = {1571-0661},
doi = {https://doi.org/10.1016/j.entcs.2016.09.026},
url = {https://www.sciencedirect.com/science/article/pii/S1571066116300718},
author = {Michael Todinov},
keywords = {stochastic pruning, stochastic flow networks, production availability, repairable flow networks, performance, software tool, simulation},
abstract = {A powerful method referred to as stochastic pruning is introduced for analysing the performance of common complex systems whose component failures follow a homogeneous Poisson process. The method has been applied to create a very fast solver for estimating the production availability of large repairable flow networks with complex topology. It is shown that the key performance measures production availability and system reliability are all properties of a stochastically pruned network with corresponding pruning probabilities. The high-speed solver is based on an important result regarding the average total output of a repairable system including components characterised by constant failure/hazard rates. The average output over a specified operation time interval is given by the ratio of the expected momentary output of the stochastically pruned system, where the separate components are pruned with probabilities equal to their unavailabilities, and the maximum momentary output in the absence of component failures. The running time of the algorithm for determining the expected total output of the system over a specified time interval is independent of the length of the operational interval and the failure frequencies of the edges. The high-speed solver has been embedded in a software tool, with graphics user interface by which a flow network topology is drawn on screen and the parameters characterising the edges and the nodes are easily specified. The software tool has been used to analyse a gas production network and to study the impact of the network topology on the network performance. It is shown that two networks built with identical type and number of components may have very different performance levels, because of slight differences in their topology.}
}

%78
@article{WANG2016125,
title = {Efficient Image Stitching through Mobile Offloading},
journal = {Electronic Notes in Theoretical Computer Science},
volume = {327},
pages = {125-146},
year = {2016},
note = {The 8th International Workshop on Practical Application of Stochastic Modeling, PASM 2016},
issn = {1571-0661},
doi = {https://doi.org/10.1016/j.entcs.2016.09.027},
url = {https://www.sciencedirect.com/science/article/pii/S157106611630072X},
author = {Qiushi Wang and Fabian Reimeier and Katinka Wolter},
keywords = {Image stitching, Mobile offloading, Program Partitioning},
abstract = {Image stitching is the task of combining images with overlapping parts to one big image. It needs a sequence of complex computation steps, especially the execution on a mobile device can take long and consume a lot of energy. Mobile offloading may alleviate those problems as it aims at improving performance and saving energy when executing complex applications on mobile devices. In this paper we investigate to which extent mobile offloading may improve the performance and energy efficiency of image stitching on mobile devices. We demonstrate our approach by stitching two or four images, but the process can be easily extended to an arbitrary number of images. We study three methods to offload parts of the computation to a resourceful server and evaluate them using several metrics. For the first offloading strategy all contributing images are sent, processed and the combined image is returned. For the second strategy images are offloaded, but not all stitching steps are executed on the remote server, and a smaller XML file is returned to the mobile client. The XML file contains a homography information which is needed by the mobile device to perform the last stitching step, the combination of the images. For the third strategy the images are transformed into grey scale before being transmitted to the server and an XML file is returned. The considered metrics are the execution time, the size of data to be transmitted and the memory usage. We find that the first strategy achieves the lowest total execution time but it requires more data to be transmitted than both the other strategies.}
}

%--------------09th PASM

%79
@article{BAYATI20185,
title = {Power Management Policy for Heterogeneous Data Center Based on Histogram and Discrete-Time MDP},
journal = {Electronic Notes in Theoretical Computer Science},
volume = {337},
pages = {5-22},
year = {2018},
note = {Proceedings of the Ninth International Workshop on the Practical Application of Stochastic Modelling (PASM)},
issn = {1571-0661},
doi = {https://doi.org/10.1016/j.entcs.2018.03.031},
url = {https://www.sciencedirect.com/science/article/pii/S1571066118300355},
author = {Marziyeh Bayati},
keywords = {Markov Decision Process, Stochastic Modeling, Energy-Aware optimization, Heterogeneous Data Centers, Digital Pollution, Queuing System},
abstract = {This work presents a stochastic model for Dynamic Power Management (DPM) that is based on switching-on/off machines in a data center of heterogeneous servers. The aim of a DPM is to ensure both a reasonable energy consumption and an acceptable Quality of Services (QoS). In this paper, arrival jobs and service rates are specified with histograms which are discrete distributions obtained from real traces, empirical data, or incoming traffic measurements. A data center is modeled by a queue, then we formulate the optimization problem by a discrete time Markov Decision Process (MDP) to find the optimal policy. We prove that the optimal policy is not hysteretic. Our approach was applied and tested for several system parameters over real Google traffic traces, when we performed a comparison between homogeneous and heterogeneous data centers.}
}

%80
@article{COHEN201823,
title = {Convex Stochastic Bounds and Stochastic Optimisation on Graphs},
journal = {Electronic Notes in Theoretical Computer Science},
volume = {337},
pages = {23-44},
year = {2018},
note = {Proceedings of the Ninth International Workshop on the Practical Application of Stochastic Modelling (PASM)},
issn = {1571-0661},
doi = {https://doi.org/10.1016/j.entcs.2018.03.032},
url = {https://www.sciencedirect.com/science/article/pii/S1571066118300367},
author = {J. Cohen and A. Fauquette and J.M. Fourneau and G.C. Noukela and N. Pekergin},
keywords = {Stochastic Convex Ordering, Discrete Distributions, Optimisation on Graphs, Stochastic PERT},
abstract = {This paper presents an approach to provide stochastic bounds for a large class of optimisation problems on graphs when the parameters (i.e. costs, weights or delays) for links are random variables. We consider the class of problems which are based on convex operators and whose complexity is polynomial, when the parameters are deterministic. Here, the parameters (for instance the delay of a link) are discrete random variables. Such an assumption drastically changes the complexity of the problem (typically, the problems turn out unfortunately to be NP-complete). We propose to give stochastic bounds (both upper and lower bounds) based on convex order. First, we prove how we can simplify a discrete distribution to obtain bounding distributions which are easier to deal with, leading to a tradeoff between the computation complexity and the accuracy of the bounds. Second, we design a polynomial time algorithm to compute an upper bound. The approach is illustrated by the computation of the execution time of a task graph.}
}

%81
@article{GRIBAUDO201845,
title = {Performance Evaluation of Replication Policies in Microservice Based Architectures},
journal = {Electronic Notes in Theoretical Computer Science},
volume = {337},
pages = {45-65},
year = {2018},
note = {Proceedings of the Ninth International Workshop on the Practical Application of Stochastic Modelling (PASM)},
issn = {1571-0661},
doi = {https://doi.org/10.1016/j.entcs.2018.03.033},
url = {https://www.sciencedirect.com/science/article/pii/S1571066118300379},
author = {Marco Gribaudo and Mauro Iacono and Daniele Manini},
keywords = {Performance evaluation, microservices},
abstract = {Nowadays applications tend to be executed on distributed environments provisioned using on-demand infrastructures. The use of techniques such as application containers simplifies the orchestration of complex systems. In this context, microservices based architectures offer a promising solution for what concerns software development and scalability. In this paper, we propose an approach to study the automatic scalability of microservices architectures deployed in public and private clouds. A Fluid Petri Net model describes the characterise of the platform, and a real trace drives the approach to consider a realistic scenario. Our focus is on evaluating the performances, costs and energy consumptions from both the service provider and infrastructure provider point of view.}
}

%82
@article{GRIBAUDO201867,
title = {Epistemic Uncertainty Propagation in Power Models},
journal = {Electronic Notes in Theoretical Computer Science},
volume = {337},
pages = {67-86},
year = {2018},
note = {Proceedings of the Ninth International Workshop on the Practical Application of Stochastic Modelling (PASM)},
issn = {1571-0661},
doi = {https://doi.org/10.1016/j.entcs.2018.03.034},
url = {https://www.sciencedirect.com/science/article/pii/S1571066118300380},
author = {Marco Gribaudo and Riccardo Pinciroli and Kishor Trivedi},
keywords = {power consumption, energy consumption, power models, epistemic uncertainty, parametric uncertainty, uncertainty propagation, M/M/c/K},
abstract = {Data-centers have recently experienced a fast growth in energy demand, mainly due to cloud computing, a paradigm that lets the users access shared computing resources (e.g., servers, storage, etc.). Several techniques have been proposed in order to alleviate this problem, and numerous power models have been adopted to predict the servers' power consumption. Some of them consider many server resources, some others account for only the CPU, that has proven to be the component responsible for the largest part of a server's power consumption. All these models work with generally inaccurate input parameters. However, none of them takes into account the effects of such inaccuracy on the model outputs. This paper investigates how epistemic (parametric) uncertainty affects a power model. Studying the impact of epistemic uncertainty on power consumption models makes it possible to consider loads with a probability density while investigating the battery depletion time or the amount of energy required for a given task.}
}

%83
@article{HORVATH201887,
title = {An Optimal Inverse Laplace Transform Method Without Positive and Negative Overshoot – An Integral Based Interpretation},
journal = {Electronic Notes in Theoretical Computer Science},
volume = {337},
pages = {87-104},
year = {2018},
note = {Proceedings of the Ninth International Workshop on the Practical Application of Stochastic Modelling (PASM)},
issn = {1571-0661},
doi = {https://doi.org/10.1016/j.entcs.2018.03.035},
url = {https://www.sciencedirect.com/science/article/pii/S1571066118300392},
author = {Illés Horváth and Zsófia Talyigás and Miklós Telek},
keywords = {numerical Inverse Laplace transformation, matrix exponential distribution, overshoot, minimal coefficient of variation},
abstract = {We propose a numerical inverse Laplace transformation method without overshoot which is derived from matrix exponential (ME) distributions with minimal coefficient of variation. We discuss the properties of the method through an integral based interpretation of numerical inverse Laplace transformation methods belonging to the Abate–Whitt framework. Compared to the previously applied non-overshooting alternative, the “Erlang” method, the error of the proposed method improves from O(1/n) to O(1/n2) while it maintains the same computational complexity.}
}

%84
@article{KAMIL2018105,
title = {Investigating the Cost of Transfer Delay on the Performance of Security in Cloud Computing},
journal = {Electronic Notes in Theoretical Computer Science},
volume = {337},
pages = {105-117},
year = {2018},
note = {Proceedings of the Ninth International Workshop on the Practical Application of Stochastic Modelling (PASM)},
issn = {1571-0661},
doi = {https://doi.org/10.1016/j.entcs.2018.03.036},
url = {https://www.sciencedirect.com/science/article/pii/S1571066118300409},
author = {Said Naser Said Kamil and Nigel Thomas},
keywords = {Communications Cost, Performance Moddelling, Performance Evaluation, PEPA, Cloud Computing},
abstract = {This study presents a performance evaluation of the deployment of partitioned workflows over hybrid clouds taking into account the cost of transfer data delay. This paper extends previous work on the cost of security in cloud computing based on the multi-level security model. This research aims to provide performance predictions of different deployment options in public and private clouds in terms of the computation and communication costs. The Markovian process algebra PEPA is used to evaluate the models behaviour under different scenarios.}
}

%85
@article{KRULL2018119,
title = {Testing Applicability of Virtual Stochastic Sensors for Non-Intrusive Appliance Load Monitoring},
journal = {Electronic Notes in Theoretical Computer Science},
volume = {337},
pages = {119-134},
year = {2018},
note = {Proceedings of the Ninth International Workshop on the Practical Application of Stochastic Modelling (PASM)},
issn = {1571-0661},
doi = {https://doi.org/10.1016/j.entcs.2018.03.037},
url = {https://www.sciencedirect.com/science/article/pii/S1571066118300410},
author = {Claudia Krull and Marcus Thiel and Graham Horton},
keywords = {Virtual Stochastic Sensors, Hidden non-Markovian Models, Non-Intrusive Appliance Load Monitoring},
abstract = {Non-intrusive appliance load monitoring (NIALM) aims at reconstructing the electricity consumption of household appliances based only on the cumulative consumption data collected via a smart meter. Various approaches have been proposed to perform NIALM including various types of Hidden Markov Model (HMM) offspring. Most do not consider the explicit duration of an appliance activation. Virtual stochastic sensors (VSS) and their underlying Hidden non-Markovian Models (HnMM) can include explicit process durations. This paper tests whether VSS can solve the NIALM task, and analyzes the methods reconstruction accuracy on the publicly available SMART* data set. Models of the household appliances with different inherent states are automatically extracted from the appliance data. The combined model, including a subset of the appliances, is then used to disaggregate the cumulative energy consumption data. Experiments show a reconstruction accuracy of up to 90% with appropriate method parameters, showing that VSS can compete with existing NIALM approaches.}
}

%86
@article{LOUNIS2018135,
title = {Stochastic-based Semantics Of Attack-Defense Trees For Security Assessment},
journal = {Electronic Notes in Theoretical Computer Science},
volume = {337},
pages = {135-154},
year = {2018},
note = {Proceedings of the Ninth International Workshop on the Practical Application of Stochastic Modelling (PASM)},
issn = {1571-0661},
doi = {https://doi.org/10.1016/j.entcs.2018.03.038},
url = {https://www.sciencedirect.com/science/article/pii/S1571066118300422},
author = {Karim Lounis},
keywords = {Graphical Security Models, Attack-Defense Trees, Attack-trees, Security Assessments, CTMCs, Stochastic Petri-nets},
abstract = {Losses caused by cyber-attacks are considerably increasing each year. The need for an optimal security assessment methodology that combines mathematical foundations with practical and user-friendly representations has become imperatively crucial. In this paper, we propose a stochastic security assessment methodology that adopts attack-defense trees model to represent security scenarios, and stochastic models to perform both qualitative and quantitative assessment. We illustrate our approach with a simple but realistic example study.}
}

%87
@article{PIHO2018155,
title = {Goals and Resource Constraints in CARMA},
journal = {Electronic Notes in Theoretical Computer Science},
volume = {337},
pages = {155-172},
year = {2018},
note = {Proceedings of the Ninth International Workshop on the Practical Application of Stochastic Modelling (PASM)},
issn = {1571-0661},
doi = {https://doi.org/10.1016/j.entcs.2018.03.039},
url = {https://www.sciencedirect.com/science/article/pii/S1571066118300434},
author = {Paul Piho and Anastasis Georgoulas and Jane Hillston},
keywords = {Stochastic modelling, collective adaptive systems, goals, control},
abstract = {Carma is a recently developed, high-level quantitative modelling language developed for the design and analysis of collective adaptive systems. In the current Carma language, agents within a system consist of a behaviour, captured as a process, and knowledge, represented as a store of attributes. In this paper we present the first steps to equipping agent specifications with more sophisticated forms of knowledge in terms of goals and targets, and demonstrate how these may be integrated into the modelling and analysis process. We illustrate the ideas with a simple example taken from the domain of swarm robotics.}
}

%88
@article{POSTEMA2018173,
title = {Evaluation of Advanced Data Centre Power Management Strategies},
journal = {Electronic Notes in Theoretical Computer Science},
volume = {337},
pages = {173-191},
year = {2018},
note = {Proceedings of the Ninth International Workshop on the Practical Application of Stochastic Modelling (PASM)},
issn = {1571-0661},
doi = {https://doi.org/10.1016/j.entcs.2018.03.040},
url = {https://www.sciencedirect.com/science/article/pii/S1571066118300446},
author = {Björn F. Postema and Boudewijn R. Haverkort},
keywords = {power management, strategies, qualities, evaluation, stability, efficiency, adaptability, robustness, discrete-event simulation, agent-based simulation, data centre},
abstract = {In recent work, we proposed a new specification language for power management strategies as an extension to our AnyLogic-based simulation framework for the trade-off analysis of power and performance in data centres. In this paper, we study the quality of such advanced power management strategies based on both power and performance measurement data collected during system operation. These strategies take a wide variety of state variables into account. In order to ensure the quality of new strategies, they are studied for stability, efficiency, adaptability and robustness; these qualities will be formally defined. This paper presents an evaluation approach for these qualities for several power management strategies inspired by strategies presented in the literature (and extensions thereof). We show that the choice of power management strategy depends both on which qualities are given the highest priority and on the used state information. The new power management strategies show significant reductions in energy consumption in our case of up to 54% energy (compared to an “always on” strategy) for a typical data centre workload for a small 30-server cluster.}
}

%--------------10th PASM

%89
@article{ALMUTAIRI20205,
title = {Performance Modelling of the Impact of Cyber Attacks on a Web-based Sales System},
journal = {Electronic Notes in Theoretical Computer Science},
volume = {353},
pages = {5-20},
year = {2020},
note = {Tenth International Workshop on the Practical Application of Stochastic Modelling (PASM)},
issn = {1571-0661},
doi = {https://doi.org/10.1016/j.entcs.2020.09.016},
url = {https://www.sciencedirect.com/science/article/pii/S1571066120300712},
author = {Ohud Almutairi and Nigel Thomas},
keywords = {Performance Models, PEPA, Cyber-Attacks},
abstract = {In this paper we present two performance models of a web-based sales system, one without the presence of an attack and the other with the presence of a denial of service attack. Models are formulated using the PEPA formalism. The PEPA eclipse plug-in is used to support the creation of the PEPA models for the web-based sales system and the automatic calculation of the performance measures identified to evaluate the models. The evaluation of the models illustrates how the performance of the warehouse's sale is negatively affected by denial of service attack through preventing some or all customers' orders from being fulfilled. The resultant delay on selling perishable products would result on products being discarded.}
}

%90
@article{ALSSAIARI202021,
title = {Energy Consumption by Servers under Unknown Service Demand},
journal = {Electronic Notes in Theoretical Computer Science},
volume = {353},
pages = {21-38},
year = {2020},
note = {Tenth International Workshop on the Practical Application of Stochastic Modelling (PASM)},
issn = {1571-0661},
doi = {https://doi.org/10.1016/j.entcs.2020.09.017},
url = {https://www.sciencedirect.com/science/article/pii/S1571066120300724},
author = {Ali Alssaiari and Nigel Thomas},
keywords = {Energy Consumption, Performance, Modelling, PEPA},
abstract = {We evaluate energy consumption under unknown service demands using three policies: task assignment based on guessing size (TAGS), the shortest queue strategy and random allocation in a homogeneous environment. We modelled these policies using performance evaluation processing algebra (PEPA) to derive numerical solutions. Our results show that servers running under TAGS consumes more energy than other policies in terms of total energy consumption. In contrast, TAGS consumes less energy than random allocation in terms of energy per job when the arrival rate is high and the job size is variable.}
}

%91
@article{ARNABOLDI202039,
title = {Modelling Load-Changing Attacks in Cyber-Physical Systems},
journal = {Electronic Notes in Theoretical Computer Science},
volume = {353},
pages = {39-60},
year = {2020},
note = {Tenth International Workshop on the Practical Application of Stochastic Modelling (PASM)},
issn = {1571-0661},
doi = {https://doi.org/10.1016/j.entcs.2020.09.018},
url = {https://www.sciencedirect.com/science/article/pii/S1571066120300736},
author = {Luca Arnaboldi and Ricardo M. Czekster and Charles Morisset and Roberto Metere},
keywords = {Coordinated Load-Changing Attacks, Smart Grid, Load Balancing Systems, Continuous Time Markov Chains},
abstract = {Cyber-Physical Systems (CPS) are present in many settings addressing a myriad of purposes. Examples are Internet-of-Things (IoT) or sensing software embedded in appliances or even specialised meters that measure and respond to electricity demands in smart grids. Due to their pervasive nature, they are usually chosen as recipients for larger scope cyber-security attacks. Those promote system-wide disruptions and are directed towards one key aspect such as confidentiality, integrity, availability or a combination of those characteristics. Our paper focuses on a particular and distressing attack where coordinated malware infected IoT units are maliciously employed to synchronously turn on or off high-wattage appliances, affecting the grid's primary control management. Our model could be extended to larger (smart) grids, Active Buildings as well as similar infrastructures. Our approach models Coordinated Load-Changing Attacks (CLCA) also referred as GridLock or BlackIoT, against a theoretical power grid, containing various types of power plants. It employs Continuous-Time Markov Chains where elements such as Power Plants and Botnets are modelled under normal or attack situations to evaluate the effect of CLCA in power reliant infrastructures. We showcase our modelling approach in the scenario of a power supplier (e.g. power plant) being targeted by a botnet. We demonstrate how our modelling approach can quantify the impact of a botnet attack and be abstracted for any CPS system involving power load management in a smart grid. Our results show that by prioritising the type of power-plants, the impact of the attack may change: in particular, we find the most impacting attack times and show how different strategies impact their success. We also find the best power generator to use depending on the current demand and strength of attack.}
}

%92
@article{BARBIERATO202061,
title = {Evaluating the Safety of Crowds in Enclosed Spaces by Markovian Agents},
journal = {Electronic Notes in Theoretical Computer Science},
volume = {353},
pages = {61-75},
year = {2020},
note = {Tenth International Workshop on the Practical Application of Stochastic Modelling (PASM)},
issn = {1571-0661},
doi = {https://doi.org/10.1016/j.entcs.2020.09.019},
url = {https://www.sciencedirect.com/science/article/pii/S1571066120300748},
author = {Enrico Barbierato and Marco Gribaudo and Mauro Iacono and Alexander H. Levis},
keywords = {Crowd motion, fire, closed spaces, Markovian Agents},
abstract = {Different paradigms have been used to model the behaviour of pedestrians in a crowd. While some approaches analyze the modelization of crowd motion from a physical perspective, other techniques prefer to focus on similar abstractions following classic paradigms, such as mobile agents or cellular automata, or even from the point of view of social forces interaction. Particular interest has emerged around the topic of crowd behaviour under condition of stress caused by a dramatic event, such as an earthquake, a terrorist attack or a fire. This paper presents a novel approach including a GSPN to describe the behaviour of an individual, which is subsequently translated into a set of Markovian Agents. The model under study reproduces a scenario where a fire, developed in a closed environment, triggers erratic crowd behaviour. It is possible to perceive that a panic situation can be mitigated by enforcing certain measures involving human leaders or small embedded systems (such as Internet-of-things enabled devices), reducing the level of risk related to safety.}
}

%93
@article{ECHABBI202077,
title = {Stochastic Bounds for the Max Flow in a Network with Discrete Random Capacities},
journal = {Electronic Notes in Theoretical Computer Science},
volume = {353},
pages = {77-105},
year = {2020},
note = {Tenth International Workshop on the Practical Application of Stochastic Modelling (PASM)},
issn = {1571-0661},
doi = {https://doi.org/10.1016/j.entcs.2020.10.014},
url = {https://www.sciencedirect.com/science/article/pii/S1571066120300906},
author = {L. Echabbi and J.M. Fourneau and O. Gacem and H. Lotfi and N. Pekergin},
keywords = {Maximal flow, Random capacity, Stochastic ordering, Increasing convex ordering},
abstract = {We show how to obtain stochastic bounds for the strong stochastic ordering and the concave ordering of the maximal flow in a network where the capacities are non negative discrete random variables. While the deterministic problem is polynomial, the stochastic version with discrete random variables is NP-hard. The monotonicity of the Min-Cut problem for these stochastic orderings allows us to simplify the input distributions and obtain bounds on the results. Thus we obtain a tradeoff between the complexity of the computations and the precision of the bounds. We illustrate the approach with some examples.}
}

%94
@article{CAMPANILE2020107,
title = {On Performance Evaluation of Security Monitoring in Multitenant Cloud Applications},
journal = {Electronic Notes in Theoretical Computer Science},
volume = {353},
pages = {107-127},
year = {2020},
note = {Tenth International Workshop on the Practical Application of Stochastic Modelling (PASM)},
issn = {1571-0661},
doi = {https://doi.org/10.1016/j.entcs.2020.09.020},
url = {https://www.sciencedirect.com/science/article/pii/S157106612030075X},
author = {Lelio Campanile and Mauro Iacono and Stefano Marrone and Michele Mastroianni},
keywords = {Simulation, Multiformalism modeling, Multitenant, Cloud, Performance evaluation},
abstract = {In this paper we present a modeling approach suitable for practical evaluation of the delays that may affect security monitoring systems in (multitenant) cloud based architecture, and in general to support professionals in planning and evaluating relevant parameters in dealing with new designs or migration projects. The approach is based on modularity and multiformalism techniques to manage complexity and guide designers in an incremental process, to help transferring technical knowledge into modeling practice and to help easing the use of simulation. We present a case study based on a real experience, triggered by a new legal requirement that Italian Public Administration should comply about their datacenters.}
}

%95
@article{SOLTANIEH2020129,
title = {Compositional Model Checking and Model Repair for a Class of Product Form Models},
journal = {Electronic Notes in Theoretical Computer Science},
volume = {353},
pages = {129-148},
year = {2020},
note = {Tenth International Workshop on the Practical Application of Stochastic Modelling (PASM)},
issn = {1571-0661},
doi = {https://doi.org/10.1016/j.entcs.2020.09.021},
url = {https://www.sciencedirect.com/science/article/pii/S1571066120300761},
author = {Amin Soltanieh and Markus Siegle},
keywords = {Markov Chain, Product Form, Compositional Analysis, Probabilistic Model Checking, Continuous Stochastic Logic (CSL), Model Repair},
abstract = {In the area of Markovian quantitative modelling, compositional model specification techniques such as Stochastic Process Algebra are widely used. However, exploiting a model's compositional structure for efficient analysis is still a difficult problem and mostly limited to special cases. This paper addresses some important issues in the area of compositional model checking of Markovian models for models with Boucherie-type product form. It closes a long-standing gap concerning the question whether compositional model checking of so-called global time-unbounded Until formulas is possible. The answer to this turns out to be negative. The paper then turns to the area of model repair, i.e. the question of how to fix a model in case it violates a given requirement. Here another general result and a useful proposition for compositional model repair are provided.}
}
